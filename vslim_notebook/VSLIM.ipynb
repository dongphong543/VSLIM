{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjlZTFZB4pNS",
        "outputId": "6f551098-21ad-44d8-bd69-231a671f0061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "W__Cpg2Yv2JQ"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q transformers==4.41.0 seqeval scikit-learn torch torchcrf pytorch-crf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-WQjoWs2dlx",
        "outputId": "dd0899de-1b71-4f9d-c396-11cf522bbd45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_vped_beta2\n",
            "/content/drive/MyDrive/dataset/slim/train_vped_beta2:\n"
          ]
        }
      ],
      "source": [
        "!ls -R \"/content/drive\" | grep train_vped_beta2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "A2l0nyt2xWEt"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/dataset/vped/train\"\n",
        "TEST_DIR = \"/content/drive/MyDrive/dataset/vped/test\"\n",
        "DEV_DIR = \"/content/drive/MyDrive/dataset/vped/dev\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dCxYX2t2Nvq",
        "outputId": "577f27bf-7856-423c-a5fb-d7593c1733c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Listing: /content/drive/MyDrive/dataset/vped\n",
            " - 'README.md'\n",
            " - 'train-dev-statistics.txt'\n",
            " - 'slot_label.txt'\n",
            " - 'intent_label.txt'\n",
            " - 'test'\n",
            " - 'dev'\n",
            " - 'train'\n",
            "\n",
            "Listing: /content/drive/MyDrive/dataset/vped/train\n",
            " - 'seq_in.txt'\n",
            " - 'seq_out.txt'\n",
            " - 'seq_intent_out.txt'\n",
            " - 'label.txt'\n",
            "\n",
            "Listing: /content/drive/MyDrive/dataset/vped/dev\n",
            " - 'seq_in.txt'\n",
            " - 'label.txt'\n",
            " - 'seq_intent_out.txt'\n",
            " - 'seq_out.txt'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "BASE_DIR = \"/content/drive/MyDrive/dataset/vped\"\n",
        "\n",
        "for p in (BASE_DIR, DATA_DIR, DEV_DIR,):\n",
        "    print(\"\\nListing:\", p)\n",
        "    for f in os.listdir(p):\n",
        "        print(\" -\", repr(f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "f9gLF73bwEpF"
      },
      "outputs": [],
      "source": [
        "# ======================\n",
        "# 1) IMPORTS & CONSTANTS\n",
        "# ======================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
        "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
        "from seqeval.metrics import f1_score as seq_f1\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from torchcrf import CRF\n",
        "from seqeval.metrics.sequence_labeling import get_entities\n",
        "\n",
        "# Model and training configuration\n",
        "MODEL_NAME = \"vinai/phobert-base-v2\"\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "LR = 5e-5\n",
        "WEIGHT_DECAY = 0.01\n",
        "SEED = 36\n",
        "IGNORE_INDEX = -100\n",
        "NUM_MASK = 4  # Maximum number of slot entities per utterance\n",
        "\n",
        "W_SLOT = 2.0 # cũ 2.0\n",
        "W_TOKINTENT = 2.0\n",
        "W_UTTINTENT = 1.0\n",
        "W_TAGINTENT = 1.0\n",
        "\n",
        "# Inference threshold\n",
        "UTT_THRESHOLD = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EZAyDVhqafM",
        "outputId": "fcda710d-6b5d-48c1-fbf5-8f21a922a823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading label schema from config files...\n",
            "Loaded 5 intent labels from /content/drive/MyDrive/dataset/vped/intent_label.txt\n",
            "Loaded 17 slot labels from /content/drive/MyDrive/dataset/vped/slot_label.txt\n",
            "\n",
            "📋 Label Schema Summary:\n",
            "  - Intent labels (5): ['add_expense', 'update_expense', 'delete_expense', 'search_expense', 'stat_expense']\n",
            "  - Slot labels (17): first 10 = ['O', 'B-target_date', 'I-target_date', 'B-target_price', 'I-target_price', 'B-target_description', 'I-target_description', 'B-target_location', 'I-target_location', 'B-condition_date']\n",
            "  - Token-intent labels (6): ['O', 'add_expense', 'update_expense', 'delete_expense', 'search_expense', 'stat_expense']\n",
            "  - Tag-intent labels (6): ['PAD', 'add_expense', 'update_expense', 'delete_expense', 'search_expense', 'stat_expense']\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# 2) LOAD LABEL SCHEMA FROM FILES\n",
        "# ================================\n",
        "\n",
        "def load_labels_from_file(file_path: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Load labels from text file (one label per line)\n",
        "    \"\"\"\n",
        "    labels = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line and not line.startswith(\"#\"):  # Skip empty lines and comments\n",
        "                labels.append(line)\n",
        "    return labels\n",
        "\n",
        "# Config file paths\n",
        "INTENT_LABEL_FILE = \"/content/drive/MyDrive/dataset/vped/intent_label.txt\"\n",
        "SLOT_LABEL_FILE = \"/content/drive/MyDrive/dataset/vped/slot_label.txt\"\n",
        "\n",
        "# Load labels from files\n",
        "print(\"Loading label schema from config files...\")\n",
        "try:\n",
        "    INTENT_LABELS = load_labels_from_file(INTENT_LABEL_FILE)\n",
        "    SLOT_LABELS = load_labels_from_file(SLOT_LABEL_FILE)\n",
        "\n",
        "    print(f\"Loaded {len(INTENT_LABELS)} intent labels from {INTENT_LABEL_FILE}\")\n",
        "    print(f\"Loaded {len(SLOT_LABELS)} slot labels from {SLOT_LABEL_FILE}\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: Config file not found - {e}\")\n",
        "    raise\n",
        "\n",
        "# Generate token-intent labels (O + intents)\n",
        "TOKEN_INTENT_LABELS = [\"O\"] + INTENT_LABELS\n",
        "\n",
        "# Add PAD for tag-intent\n",
        "INTENT_LABELS_WITH_PAD = [\"PAD\"] + INTENT_LABELS\n",
        "\n",
        "# Create mappings\n",
        "INTENT2ID = {intent: i for i, intent in enumerate(INTENT_LABELS)}\n",
        "ID2INTENT = {i: intent for intent, i in INTENT2ID.items()}\n",
        "\n",
        "SLOT2ID = {slot: i for i, slot in enumerate(SLOT_LABELS)}\n",
        "ID2SLOT = {i: slot for slot, i in SLOT2ID.items()}\n",
        "\n",
        "TOKINT2ID = {tokint: i for i, tokint in enumerate(TOKEN_INTENT_LABELS)}\n",
        "ID2TOKINT = {i: tokint for tokint, i in TOKINT2ID.items()}\n",
        "\n",
        "TAGINT2ID = {intent: i for i, intent in enumerate(INTENT_LABELS_WITH_PAD)}\n",
        "ID2TAGINT = {i: intent for intent, i in TAGINT2ID.items()}\n",
        "\n",
        "print(f\"\\n📋 Label Schema Summary:\")\n",
        "print(f\"  - Intent labels ({len(INTENT_LABELS)}): {INTENT_LABELS}\")\n",
        "print(f\"  - Slot labels ({len(SLOT_LABELS)}): first 10 = {SLOT_LABELS[:10]}\")\n",
        "print(f\"  - Token-intent labels ({len(TOKEN_INTENT_LABELS)}): {TOKEN_INTENT_LABELS}\")\n",
        "print(f\"  - Tag-intent labels ({len(INTENT_LABELS_WITH_PAD)}): {INTENT_LABELS_WITH_PAD}\")\n",
        "\n",
        "# Set random seed\n",
        "def set_seed(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(SEED)\n",
        "DEVICE = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "HyQ3c662wXh9"
      },
      "outputs": [],
      "source": [
        "# =================\n",
        "# 3) MODULE CLASSES\n",
        "# =================\n",
        "\n",
        "class MultiIntentClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_intent_labels, dropout_rate=0.):\n",
        "        super(MultiIntentClassifier, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.linear = nn.Linear(input_dim, num_intent_labels)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.reset_params()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "    def reset_params(self):\n",
        "        nn.init.uniform_(self.linear.weight)\n",
        "        nn.init.uniform_(self.linear.bias)\n",
        "\n",
        "class SlotClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_slot_labels, dropout_rate=0.2):\n",
        "        super(SlotClassifier, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.linear = nn.Linear(input_dim, num_slot_labels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        return self.linear(x)\n",
        "\n",
        "class IntentTokenClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_intent_labels, dropout_rate=0.):\n",
        "        super(IntentTokenClassifier, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.linear = nn.Linear(input_dim, num_intent_labels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        return self.linear(x)\n",
        "\n",
        "class TagIntentClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_intent_labels, dropout_rate=0.):\n",
        "        super(TagIntentClassifier, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.linear = nn.Linear(input_dim, num_intent_labels)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        return self.softmax(self.linear(x))\n",
        "\n",
        "\n",
        "class BiaffineTagIntentClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Biaffine Tag-Intent Classifier\n",
        "    score = h_cls^T U r + W [h_cls; r] + b\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, num_intent_labels, dropout_rate=0.):\n",
        "        super(BiaffineTagIntentClassifier, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.num_intent_labels = num_intent_labels\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Bilinear term: U (input_dim x input_dim x num_intent_labels)\n",
        "        self.U = nn.Parameter(torch.Tensor(num_intent_labels, input_dim, input_dim))\n",
        "\n",
        "        # Linear term: W (2*input_dim x num_intent_labels)\n",
        "        self.W = nn.Linear(2 * input_dim, num_intent_labels)\n",
        "\n",
        "        # Softmax\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "        self.reset_params()\n",
        "\n",
        "    def forward(self, h_cls, r):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            h_cls: [batch*num_mask, hidden_dim] - CLS representations\n",
        "            r: [batch*num_mask, hidden_dim] - tag intent vectors\n",
        "\n",
        "        Returns:\n",
        "            [batch*num_mask, num_intent_labels] - probabilities\n",
        "        \"\"\"\n",
        "        h_cls = self.dropout(h_cls)\n",
        "        r = self.dropout(r)\n",
        "\n",
        "        # Bilinear term: h_cls^T U r\n",
        "        # h_cls: [B, H], U: [C, H, H], r: [B, H]\n",
        "        # Result: [B, C]\n",
        "        bilinear_scores = torch.einsum('bh,chd,bd->bc', h_cls, self.U, r)\n",
        "\n",
        "        # Linear term: W [h_cls; r]\n",
        "        concat = torch.cat([h_cls, r], dim=1)  # [B, 2H]\n",
        "        linear_scores = self.W(concat)  # [B, C]\n",
        "\n",
        "        # Total score\n",
        "        scores = bilinear_scores + linear_scores\n",
        "\n",
        "        return self.softmax(scores)\n",
        "\n",
        "    def reset_params(self):\n",
        "        nn.init.xavier_uniform_(self.U)\n",
        "        nn.init.xavier_uniform_(self.W.weight)\n",
        "        nn.init.zeros_(self.W.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2578ViScwYLc"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 4) MAIN MODEL (EXACT PAPER ARCHITECTURE)\n",
        "# ================================\n",
        "\n",
        "class VSLIM(nn.Module):\n",
        "    \"\"\"\n",
        "    Features:\n",
        "    - Multi-intent classification with sigmoid\n",
        "    - Slot filling with optional CRF\n",
        "    - Intent token classification\n",
        "    - Tag-intent classification with B/BI masks\n",
        "    - Intent attention for tag-intent\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "             model_name,\n",
        "             num_slots,\n",
        "             num_intents,\n",
        "             num_token_intents,\n",
        "             num_tag_intents,\n",
        "             dropout=0.1,\n",
        "             use_crf=False,\n",
        "             num_mask=4,\n",
        "             cls_token_cat=True,\n",
        "             intent_attn=True,\n",
        "             use_biaffine_tag_intent=True):\n",
        "      super().__init__()\n",
        "\n",
        "      # PhoBERT encoder\n",
        "      self.encoder = AutoModel.from_pretrained(model_name)\n",
        "      hidden_size = self.encoder.config.hidden_size\n",
        "\n",
        "      # Classification heads\n",
        "      self.multi_intent_classifier = MultiIntentClassifier(hidden_size, num_intents, dropout)\n",
        "      self.slot_classifier = SlotClassifier(hidden_size, num_slots, dropout)\n",
        "      self.intent_token_classifier = IntentTokenClassifier(hidden_size, num_token_intents, dropout)\n",
        "\n",
        "      # Tag-intent classifier: Biaffine or Linear\n",
        "      self.use_biaffine_tag_intent = use_biaffine_tag_intent\n",
        "\n",
        "      if use_biaffine_tag_intent:\n",
        "          # Biaffine classifier: both h_cls và r have dim = hidden_size\n",
        "          self.biaffine_tag_intent_classifier = BiaffineTagIntentClassifier(\n",
        "              hidden_size, num_tag_intents, dropout\n",
        "          )\n",
        "      else:\n",
        "          # Linear classifier (concat [CLS; r])\n",
        "          tag_input_dim = 2 * hidden_size if cls_token_cat else hidden_size\n",
        "          self.tag_intent_classifier = TagIntentClassifier(tag_input_dim, num_tag_intents, dropout)\n",
        "\n",
        "      if use_crf:\n",
        "          self.crf = CRF(num_tags=num_slots, batch_first=True)\n",
        "\n",
        "      self.use_crf = use_crf\n",
        "      self.num_mask = num_mask\n",
        "      self.cls_token_cat = cls_token_cat\n",
        "      self.intent_attn = intent_attn\n",
        "      self.num_intents = num_intents\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids=None,\n",
        "                intent_label_ids=None, slot_labels_ids=None,\n",
        "                intent_token_ids=None, B_tag_mask=None, BI_tag_mask=None,\n",
        "                tag_intent_label=None):\n",
        "        # Encode with PhoBERT\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = outputs.last_hidden_state  # [batch, seq_len, hidden]\n",
        "        pooled_output = outputs.pooler_output        # [batch, hidden]\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        # ==================================== 1. Multi-Intent Classification ========================================\n",
        "        intent_logits = self.multi_intent_classifier(pooled_output)  # [batch, num_intents]\n",
        "\n",
        "        if intent_label_ids is not None:\n",
        "            intent_loss_fct = nn.BCELoss()\n",
        "            intent_loss = intent_loss_fct(intent_logits + 1e-10, intent_label_ids)\n",
        "            total_loss += W_UTTINTENT * intent_loss\n",
        "\n",
        "        # ==================================== 2. Slot Classification ========================================\n",
        "        slot_logits = self.slot_classifier(sequence_output)  # [batch, seq_len, num_slots]\n",
        "\n",
        "        if slot_labels_ids is not None:\n",
        "            if self.use_crf:\n",
        "                slot_loss = self.crf(slot_logits, slot_labels_ids, mask=attention_mask.byte(), reduction='mean')\n",
        "                slot_loss = -1 * slot_loss  # negative log-likelihood\n",
        "            else:\n",
        "                slot_loss_fct = nn.CrossEntropyLoss(ignore_index=IGNORE_INDEX)\n",
        "                if attention_mask is not None:\n",
        "                    active_loss = attention_mask.view(-1) == 1\n",
        "                    active_logits = slot_logits.view(-1, slot_logits.size(-1))[active_loss]\n",
        "                    active_labels = slot_labels_ids.view(-1)[active_loss]\n",
        "                    slot_loss = slot_loss_fct(active_logits, active_labels)\n",
        "                else:\n",
        "                    slot_loss = slot_loss_fct(slot_logits.view(-1, slot_logits.size(-1)), slot_labels_ids.view(-1))\n",
        "\n",
        "            total_loss += W_SLOT * slot_loss\n",
        "\n",
        "        # ==================================== 3. Intent Token Classification ========================================\n",
        "        intent_token_logits = self.intent_token_classifier(sequence_output)\n",
        "\n",
        "        intent_token_loss = 0.0\n",
        "        if intent_token_ids is not None:\n",
        "            if self.use_crf:\n",
        "                intent_token_loss = self.crf(intent_token_logits, intent_token_ids, mask=attention_mask.byte(), reduction='mean')\n",
        "                intent_token_loss = -1 * intent_token_loss\n",
        "            else:\n",
        "                intent_token_loss_fct = nn.CrossEntropyLoss(ignore_index=IGNORE_INDEX)\n",
        "                if attention_mask is not None:\n",
        "                    active_intent_loss = attention_mask.view(-1) == 1\n",
        "                    active_intent_logits = intent_token_logits.view(-1, intent_token_logits.size(-1))[active_intent_loss]\n",
        "                    active_intent_tokens = intent_token_ids.view(-1)[active_intent_loss]\n",
        "                    intent_token_loss = intent_token_loss_fct(active_intent_logits, active_intent_tokens)\n",
        "                else:\n",
        "                    intent_token_loss = intent_token_loss_fct(intent_token_logits.view(-1, intent_token_logits.size(-1)), intent_token_ids.view(-1))\n",
        "\n",
        "            total_loss += W_TOKINTENT * intent_token_loss\n",
        "\n",
        "        # ==================================== 4. Tag-Intent Classification ========================================\n",
        "        tag_intent_loss = 0.0\n",
        "        tag_intent_logits = None\n",
        "\n",
        "        if B_tag_mask is not None and BI_tag_mask is not None and tag_intent_label is not None:\n",
        "            if BI_tag_mask.type() != torch.cuda.FloatTensor:\n",
        "                BI_tag_mask = BI_tag_mask.type(torch.cuda.FloatTensor)\n",
        "            if B_tag_mask.type() != torch.cuda.FloatTensor:\n",
        "                B_tag_mask = B_tag_mask.type(torch.cuda.FloatTensor)\n",
        "\n",
        "            # Use BI_tag_mask for weighted pooling\n",
        "            tag_intent_vec = torch.einsum('bml,bld->bmd', BI_tag_mask, sequence_output)  # [batch, num_mask, hidden]\n",
        "\n",
        "            # BIAFFINE TAG-INTENT CLASSIFICATION\n",
        "            if self.use_biaffine_tag_intent:\n",
        "                # h_cls: pooled_output [batch, hidden]\n",
        "                h_cls = pooled_output.unsqueeze(1)  # [batch, 1, hidden]\n",
        "                h_cls = h_cls.repeat(1, self.num_mask, 1)  # [batch, num_mask, hidden]\n",
        "\n",
        "                # r: tag_intent_vec [batch, num_mask, hidden]\n",
        "                batch_size = h_cls.size(0)\n",
        "                h_cls_flat = h_cls.view(batch_size * self.num_mask, -1)  # [batch*num_mask, hidden]\n",
        "                r_flat = tag_intent_vec.view(batch_size * self.num_mask, -1)  # [batch*num_mask, hidden]\n",
        "\n",
        "                # Biaffine classification\n",
        "                tag_intent_logits = self.biaffine_tag_intent_classifier(h_cls_flat, r_flat)  # [batch*num_mask, num_tag_intents]\n",
        "\n",
        "            else:\n",
        "                if self.cls_token_cat:\n",
        "                    cls_token = pooled_output.unsqueeze(1)  # [batch, 1, hidden]\n",
        "                    cls_token = cls_token.repeat(1, self.num_mask, 1)  # [batch, num_mask, hidden]\n",
        "                    tag_intent_vec = torch.cat((cls_token, tag_intent_vec), dim=2)  # [batch, num_mask, 2*hidden]\n",
        "\n",
        "                tag_intent_vec = tag_intent_vec.view(tag_intent_vec.size(0) * tag_intent_vec.size(1), -1)\n",
        "                tag_intent_logits = self.tag_intent_classifier(tag_intent_vec)  # [batch*num_mask, num_tag_intents]\n",
        "\n",
        "            if self.intent_attn:\n",
        "                intent_probs = intent_logits.unsqueeze(1)  # [batch, 1, num_intents]\n",
        "                intent_probs = intent_probs.repeat(1, self.num_mask, 1)  # [batch, num_mask, num_intents]\n",
        "                intent_probs = intent_probs.view(intent_probs.size(0) * intent_probs.size(1), -1)  # [batch*num_mask, num_intents]\n",
        "\n",
        "                # Add PAD dimension to intent_probs\n",
        "                pad_probs = torch.zeros(intent_probs.size(0), 1, device=intent_probs.device)  # [batch*num_mask, 1] for PAD\n",
        "                intent_probs_expanded = torch.cat([pad_probs, intent_probs], dim=1)  # [batch*num_mask, 6]\n",
        "\n",
        "                # Apply attention weighting\n",
        "                tag_intent_logits = tag_intent_logits * intent_probs_expanded\n",
        "                tag_intent_logits = tag_intent_logits.div(tag_intent_logits.sum(dim=1, keepdim=True) + 1e-10)\n",
        "\n",
        "            nll_fct = nn.NLLLoss(ignore_index=IGNORE_INDEX)\n",
        "            tag_intent_loss = nll_fct(torch.log(tag_intent_logits + 1e-10), tag_intent_label.view(-1))\n",
        "            total_loss += W_TAGINTENT * tag_intent_loss\n",
        "\n",
        "        return {\n",
        "            \"total_loss\": total_loss,\n",
        "            \"intent_loss\": intent_loss if intent_label_ids is not None else 0,\n",
        "            \"slot_loss\": slot_loss if slot_labels_ids is not None else 0,\n",
        "            \"intent_token_loss\": intent_token_loss,\n",
        "            \"tag_intent_loss\": tag_intent_loss,\n",
        "            \"intent_logits\": intent_logits,\n",
        "            \"slot_logits\": slot_logits,\n",
        "            \"intent_token_logits\": intent_token_logits, # if intent_token_ids is not None else None,\n",
        "            \"tag_intent_logits\": tag_intent_logits if B_tag_mask is not None else None\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy2HYILYwa_5",
        "outputId": "98f91f33-e878-4143-db04-5d2bf9ec7c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 1014 examples from /content/drive/MyDrive/dataset/vped/train\n",
            "Sample: tokens=['Còn', 'cái', 'viettel', 'đầu', 'năm'], intents=['add_expense', 'delete_expense'], slots=['O', 'O', 'B-condition_description', 'B-condition_date', 'I-condition_date']\n",
            "Loaded 210 examples from /content/drive/MyDrive/dataset/vped/dev\n",
            "Sample: tokens=['Hqua', 'mua', 'đèn', 'trên', 'tiktok'], intents=['add_expense'], slots=['B-target_date', 'O', 'B-target_description', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "# ===============\n",
        "# 5) DATA LOADING\n",
        "# ===============\n",
        "\n",
        "def read_lines(file_path: Path) -> List[str]:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return [line.rstrip(\"\\n\") for line in f]\n",
        "\n",
        "def resolve_file(base_dir: Path, name: str) -> Path:\n",
        "    candidates = [base_dir / name, base_dir / f\"{name}.txt\"]\n",
        "    for path in candidates:\n",
        "        if path.exists():\n",
        "            return path\n",
        "    raise FileNotFoundError(f\"Cannot find {name}(.txt) in {base_dir}\")\n",
        "\n",
        "def load_data_with_masks(data_dir: str, is_test: bool = False) -> Tuple:\n",
        "    \"\"\"\n",
        "    Load data with B/BI masks for tag-intent\n",
        "    \"\"\"\n",
        "    base = Path(data_dir)\n",
        "\n",
        "    # Load files seq, label, seq_intent\n",
        "    seq_in_path = resolve_file(base, \"seq_in\")\n",
        "    label_path = resolve_file(base, \"label\")\n",
        "    seq_out_path = resolve_file(base, \"seq_out\")\n",
        "    seq_intent_path = resolve_file(base, \"seq_intent_out\")\n",
        "\n",
        "    seq_in_lines = read_lines(seq_in_path)\n",
        "    label_lines = read_lines(label_path)\n",
        "    seq_out_lines = read_lines(seq_out_path)\n",
        "    seq_intent_lines = read_lines(seq_intent_path)\n",
        "\n",
        "    n = len(seq_in_lines)\n",
        "    assert len(label_lines) == n\n",
        "    assert len(seq_out_lines) == n\n",
        "    assert len(seq_intent_lines) == n\n",
        "\n",
        "    sentences = []\n",
        "    slot_tags = []\n",
        "    token_intent_tags = []\n",
        "    utterance_intents = []\n",
        "    B_tag_masks = []\n",
        "    BI_tag_masks = []\n",
        "    tag_intent_labels = []\n",
        "\n",
        "    for i in range(n):\n",
        "        tokens = seq_in_lines[i].strip().split()\n",
        "        sentences.append(tokens)\n",
        "\n",
        "        label_line = label_lines[i].strip()\n",
        "        if label_line == \"\":\n",
        "            utterance_intents.append([\"none\"])\n",
        "        else:\n",
        "            utterance_intents.append(label_line.split(\"#\"))\n",
        "\n",
        "        slot_line = seq_out_lines[i].strip()\n",
        "        if slot_line == \"\":\n",
        "            slot_tags.append([\"O\"] * len(tokens))\n",
        "        else:\n",
        "            raw_slots = slot_line.split()\n",
        "            if len(raw_slots) < len(tokens):\n",
        "                raw_slots = raw_slots + [\"O\"] * (len(tokens) - len(raw_slots))\n",
        "            elif len(raw_slots) > len(tokens):\n",
        "                raw_slots = raw_slots[:len(tokens)]\n",
        "            slot_tags.append(raw_slots)\n",
        "\n",
        "        tokint_line = seq_intent_lines[i].strip()\n",
        "        if tokint_line == \"\":\n",
        "            token_intent_tags.append([\"O\"] * len(tokens))\n",
        "        else:\n",
        "            raw_tokints = tokint_line.split()\n",
        "            if len(raw_tokints) < len(tokens):\n",
        "                raw_tokints = raw_tokints + [\"O\"] * (len(tokens) - len(raw_tokints))\n",
        "            elif len(raw_tokints) > len(tokens):\n",
        "                raw_tokints = raw_tokints[:len(tokens)]\n",
        "            token_intent_tags.append(raw_tokints)\n",
        "\n",
        "        # Generate B/BI masks and tag-intent labels\n",
        "        entities = get_entities(slot_line.split())\n",
        "        if len(entities) > NUM_MASK:\n",
        "            entities = entities[:NUM_MASK]\n",
        "\n",
        "        B_tag_mask = [[0 for _ in range(len(tokens))] for _ in range(NUM_MASK)]\n",
        "        BI_tag_mask = [[0 for _ in range(len(tokens))] for _ in range(NUM_MASK)]\n",
        "        tag_intent_label = [TAGINT2ID[\"PAD\"] for _ in range(NUM_MASK)]\n",
        "\n",
        "        try:\n",
        "            for idx, (tag, start, end) in enumerate(entities):\n",
        "                B_tag_mask[idx][start] = 1\n",
        "                # Weighted BI mask\n",
        "                weight = 1.0 / (end - start + 1)\n",
        "                BI_tag_mask[idx][start:end+1] = [weight] * (end - start + 1)\n",
        "                # Tag intent label from token intent at start position\n",
        "                if start < len(token_intent_tags[-1]):\n",
        "                    tokint_tag = token_intent_tags[-1][start]\n",
        "                    if tokint_tag in TOKINT2ID and tokint_tag != \"O\":\n",
        "                        tag_intent_label[idx] = TAGINT2ID[tokint_tag]\n",
        "        except:\n",
        "            pass  # Keep default PAD labels\n",
        "\n",
        "        B_tag_masks.append(B_tag_mask)\n",
        "        BI_tag_masks.append(BI_tag_mask)\n",
        "        tag_intent_labels.append(tag_intent_label)\n",
        "\n",
        "    print(f\"Loaded {n} examples from {data_dir}\")\n",
        "    print(f\"Sample: tokens={sentences[0][:5]}, intents={utterance_intents[0]}, slots={slot_tags[0][:5]}\")\n",
        "\n",
        "    return (sentences, slot_tags, token_intent_tags, utterance_intents,\n",
        "            B_tag_masks, BI_tag_masks, tag_intent_labels)\n",
        "\n",
        "train_data = load_data_with_masks(DATA_DIR)\n",
        "train_sentences, train_slot_tags, train_token_intent_tags, train_utterance_intents, \\\n",
        "train_B_masks, train_BI_masks, train_tag_intent_labels = train_data\n",
        "\n",
        "dev_data = load_data_with_masks(DEV_DIR)\n",
        "dev_sentences, dev_slot_tags, dev_token_intent_tags, dev_utterance_intents, \\\n",
        "dev_B_masks, dev_BI_masks, dev_tag_intent_labels = dev_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573,
          "referenced_widgets": [
            "8e1957c93868453ea08eda21b929feff",
            "dbf0620bb1f442548beeca73ec7354f4",
            "d0ddf793a0f64829a18afb54356e1a4a",
            "d7e9912ccf6047fc898fa8fef19bf9e5",
            "208ad7e94adb4872b90e92d01d3e21dc",
            "3346a4779df54fb3aa089bc336c929ad",
            "90f274c6dfb94488af54d9260241484b",
            "16d5460ce5b2479dbf2aeb79800f9231",
            "76ecafc616aa4f4f94b2ca388f95f0da",
            "fb7815a357464954b7dbfe82f2cfb819",
            "0feaad1dfeff4d71b3f1af45c9ea25c2",
            "2db195491c5e4feb93f1922defc135f5",
            "a8a4a36d48544c9fb3130a7a7b522b47",
            "c2c5db9497024bf28e4bd4e9173ca196",
            "3ac7cc8e1d7b4aec9af40f7458747d25",
            "afd3f46d5e9c464da583b937aa160a83",
            "3bf014ae5b544acf969fd7568f3ef8da",
            "79e54c3d052847ec879c513dd0ae9694",
            "fcda3e38394c4c78a19a085ef0fee33e",
            "cffdd3e01dad415a90cd34f91d1b3113",
            "640627432f99449a9d1fe8ea967b579b",
            "fdd342be8d3244c38c41cee8a819a2e2",
            "81cdeeb6be78491a83528d7a4066cb53",
            "4f0fce78310945678831abb7cfc689d8",
            "1b133f565377494da1fbc9516d77c3f2",
            "5457a3e06236462b9d1b9c6a1c666a2b",
            "3931f37e24214398bfa1804f4c4e4170",
            "aa0d150ee7384c90923d1d27c30d8519",
            "88dbfcff1e56429daa43a67b459b7fe7",
            "1060d4416df349e4ba7442109e886476",
            "76bd0aa10b284d21b3c1bf1420001c5e",
            "273e70edb1d5432db9ba1297dee85d5e",
            "b28f107bd3c24449bcfd8250f2628f6d",
            "2cafcd1766b94c65b0c8b154ab5b4241",
            "80106b3e9a8748fabd99ab7c18b82989",
            "9d851b57e1e5434982e90ca02c5251b2",
            "26d7dc9102e24c37a80ea115eeccd3dd",
            "e574066242d240f28c03a7e09762e7ea",
            "99479b00883f44798f7a98fc624af821",
            "c9dd39faa0ac44969fd63dae4fe82942",
            "ffd8b21207f44bac8e24d9c39c41809c",
            "bcf38104039749e7b08896eb22df8723",
            "0a9a8a7248a24550b30c61bd36f54641",
            "b71cec8295cd4e40a5ebdfc968388807"
          ]
        },
        "id": "rDaXD7Wgwi1R",
        "outputId": "2573ac49-caf2-4a65-c46f-8b15085fe0b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e1957c93868453ea08eda21b929feff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/678 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2db195491c5e4feb93f1922defc135f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81cdeeb6be78491a83528d7a4066cb53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "bpe.codes: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cafcd1766b94c65b0c8b154ab5b4241",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizer: vinai/phobert-base-v2, Fast: False\n",
            "Train samples: 1014\n",
            "Val samples: 210\n",
            "Train batches: 32\n",
            "Val batches: 7\n",
            "Sample batch shapes:\n",
            "  input_ids: torch.Size([32, 128])\n",
            "  attention_mask: torch.Size([32, 128])\n",
            "  token_type_ids: torch.Size([32, 128])\n",
            "  slot_labels: torch.Size([32, 128])\n",
            "  tokint_labels: torch.Size([32, 128])\n",
            "  uttint_labels: torch.Size([32, 5])\n",
            "  B_tag_mask: torch.Size([32, 4, 128])\n",
            "  BI_tag_mask: torch.Size([32, 4, 128])\n",
            "  tag_intent_label: torch.Size([32, 4])\n",
            "VSLIM dataset ready!\n"
          ]
        }
      ],
      "source": [
        "# ================\n",
        "# 6) DATASET CLASS\n",
        "# ================\n",
        "\n",
        "class VSLIMDataset(Dataset):\n",
        "    def __init__(self, sentences, slot_tags, token_intent_tags, utterance_intents,\n",
        "                 B_masks, BI_masks, tag_intent_labels, tokenizer, max_len=MAX_LEN):\n",
        "        self.sentences = sentences\n",
        "        self.slot_tags = slot_tags\n",
        "        self.token_intent_tags = token_intent_tags\n",
        "        self.utterance_intents = utterance_intents\n",
        "        self.B_masks = B_masks\n",
        "        self.BI_masks = BI_masks\n",
        "        self.tag_intent_labels = tag_intent_labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.num_intents = len(INTENT_LABELS)\n",
        "        self.num_tag_intents = len(INTENT_LABELS_WITH_PAD)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.sentences[idx]\n",
        "        slot_labels = self.slot_tags[idx]\n",
        "        tokint_labels = self.token_intent_tags[idx]\n",
        "        utt_intents = self.utterance_intents[idx]\n",
        "        B_mask = self.B_masks[idx]\n",
        "        BI_mask = self.BI_masks[idx]\n",
        "        tag_intent_label = self.tag_intent_labels[idx]\n",
        "\n",
        "        is_none_utterance = (len(utt_intents) == 1 and utt_intents[0] == \"none\")\n",
        "\n",
        "        # Subword tokenization with alignment\n",
        "        subword_tokens = []\n",
        "        subword_slot_labels = []\n",
        "        subword_tokint_labels = []\n",
        "        subword_B_masks = []\n",
        "        subword_BI_masks = []\n",
        "\n",
        "        for token, slot_tag, tokint_tag, B_pos_mask, BI_pos_mask in zip(\n",
        "            tokens, slot_labels, tokint_labels, zip(*B_mask), zip(*BI_mask)):\n",
        "\n",
        "            pieces = self.tokenizer.tokenize(token) or [self.tokenizer.unk_token]\n",
        "            subword_tokens.extend(pieces)\n",
        "\n",
        "            # Label assignment (first subword only)\n",
        "            if is_none_utterance:\n",
        "                subword_slot_labels.extend([IGNORE_INDEX] * len(pieces))\n",
        "                subword_tokint_labels.extend([IGNORE_INDEX] * len(pieces))\n",
        "            else:\n",
        "                slot_id = SLOT2ID.get(slot_tag, SLOT2ID[\"O\"])\n",
        "                subword_slot_labels.append(slot_id)\n",
        "                subword_slot_labels.extend([IGNORE_INDEX] * (len(pieces) - 1))\n",
        "\n",
        "                if tokint_tag == \"O\":\n",
        "                    subword_tokint_labels.extend([IGNORE_INDEX] * len(pieces))\n",
        "                else:\n",
        "                    tokint_id = TOKINT2ID.get(tokint_tag, TOKINT2ID[\"O\"])\n",
        "                    subword_tokint_labels.append(tokint_id)\n",
        "                    subword_tokint_labels.extend([IGNORE_INDEX] * (len(pieces) - 1))\n",
        "\n",
        "            # B/BI masks (first subword only)\n",
        "            subword_B_masks.append(B_pos_mask)\n",
        "            subword_B_masks.extend([(0,) * NUM_MASK] * (len(pieces) - 1))\n",
        "            subword_BI_masks.append(BI_pos_mask)\n",
        "            subword_BI_masks.extend([(0.0,) * NUM_MASK] * (len(pieces) - 1))\n",
        "\n",
        "        # Convert to input IDs\n",
        "        input_ids = self.tokenizer.convert_tokens_to_ids(subword_tokens)\n",
        "        input_ids = self.tokenizer.build_inputs_with_special_tokens(input_ids)\n",
        "\n",
        "        # Add IGNORE_INDEX for special tokens\n",
        "        subword_slot_labels = [IGNORE_INDEX] + subword_slot_labels + [IGNORE_INDEX]\n",
        "        subword_tokint_labels = [IGNORE_INDEX] + subword_tokint_labels + [IGNORE_INDEX]\n",
        "        subword_B_masks = [(0,) * NUM_MASK] + subword_B_masks + [(0,) * NUM_MASK]\n",
        "        subword_BI_masks = [(0.0,) * NUM_MASK] + subword_BI_masks + [(0.0,) * NUM_MASK]\n",
        "\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        token_type_ids = [0] * len(input_ids)\n",
        "\n",
        "        # Truncate if necessary\n",
        "        if len(input_ids) > self.max_len:\n",
        "            input_ids = input_ids[:self.max_len]\n",
        "            attention_mask = attention_mask[:self.max_len]\n",
        "            token_type_ids = token_type_ids[:self.max_len]\n",
        "            subword_slot_labels = subword_slot_labels[:self.max_len]\n",
        "            subword_tokint_labels = subword_tokint_labels[:self.max_len]\n",
        "            subword_B_masks = subword_B_masks[:self.max_len]\n",
        "            subword_BI_masks = subword_BI_masks[:self.max_len]\n",
        "\n",
        "        # Pad to max_len\n",
        "        pad_len = self.max_len - len(input_ids)\n",
        "        if pad_len > 0:\n",
        "            pad_id = self.tokenizer.pad_token_id\n",
        "            input_ids.extend([pad_id] * pad_len)\n",
        "            attention_mask.extend([0] * pad_len)\n",
        "            token_type_ids.extend([0] * pad_len)\n",
        "            subword_slot_labels.extend([IGNORE_INDEX] * pad_len)\n",
        "            subword_tokint_labels.extend([IGNORE_INDEX] * pad_len)\n",
        "            subword_B_masks.extend([(0,) * NUM_MASK] * pad_len)\n",
        "            subword_BI_masks.extend([(0.0,) * NUM_MASK] * pad_len)\n",
        "\n",
        "        utt_intent_vector = torch.zeros(self.num_intents, dtype=torch.float)\n",
        "        for intent in utt_intents:\n",
        "            if intent in INTENT2ID:\n",
        "                utt_intent_vector[INTENT2ID[intent]] = 1.0\n",
        "\n",
        "        # Convert B/BI masks to proper format\n",
        "        B_mask_tensor = torch.tensor(list(zip(*subword_B_masks)), dtype=torch.long).T  # [seq_len, num_mask] -> [num_mask, seq_len]\n",
        "        BI_mask_tensor = torch.tensor(list(zip(*subword_BI_masks)), dtype=torch.float).T  # [seq_len, num_mask] -> [num_mask, seq_len]\n",
        "        tag_intent_tensor = torch.tensor(tag_intent_label, dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
        "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            \"slot_labels\": torch.tensor(subword_slot_labels, dtype=torch.long),\n",
        "            \"tokint_labels\": torch.tensor(subword_tokint_labels, dtype=torch.long),\n",
        "            \"uttint_labels\": utt_intent_vector,\n",
        "            \"B_tag_mask\": B_mask_tensor,\n",
        "            \"BI_tag_mask\": BI_mask_tensor,\n",
        "            \"tag_intent_label\": tag_intent_tensor\n",
        "        }\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return {\n",
        "        \"input_ids\": torch.stack([item[\"input_ids\"] for item in batch]),\n",
        "        \"attention_mask\": torch.stack([item[\"attention_mask\"] for item in batch]),\n",
        "        \"token_type_ids\": torch.stack([item[\"token_type_ids\"] for item in batch]),\n",
        "        \"slot_labels\": torch.stack([item[\"slot_labels\"] for item in batch]),\n",
        "        \"tokint_labels\": torch.stack([item[\"tokint_labels\"] for item in batch]),\n",
        "        \"uttint_labels\": torch.stack([item[\"uttint_labels\"] for item in batch]),\n",
        "\n",
        "        \"B_tag_mask\": torch.stack([item[\"B_tag_mask\"] for item in batch]).transpose(1, 2),  # [batch, seq_len, num_mask] -> [batch, num_mask, seq_len]\n",
        "        \"BI_tag_mask\": torch.stack([item[\"BI_tag_mask\"] for item in batch]).transpose(1, 2),  # [batch, seq_len, num_mask] -> [batch, num_mask, seq_len]\n",
        "        \"tag_intent_label\": torch.stack([item[\"tag_intent_label\"] for item in batch])\n",
        "    }\n",
        "\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)\n",
        "print(f\"Tokenizer: {MODEL_NAME}, Fast: {getattr(tokenizer, 'is_fast', False)}\")\n",
        "\n",
        "\n",
        "train_dataset = VSLIMDataset(\n",
        "    train_sentences, train_slot_tags, train_token_intent_tags, train_utterance_intents,\n",
        "    train_B_masks, train_BI_masks, train_tag_intent_labels, tokenizer, MAX_LEN\n",
        ")\n",
        "\n",
        "dev_dataset = VSLIMDataset(\n",
        "    dev_sentences, dev_slot_tags, dev_token_intent_tags, dev_utterance_intents,\n",
        "    dev_B_masks, dev_BI_masks, dev_tag_intent_labels, tokenizer, MAX_LEN\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Val samples: {len(dev_dataset)}\")\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n",
        "\n",
        "# Test data loading\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(f\"Sample batch shapes:\")\n",
        "for key, tensor in sample_batch.items():\n",
        "    print(f\"  {key}: {tensor.shape}\")\n",
        "\n",
        "print(\"VSLIM dataset ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "438c973005dd4b8d852bcd3a186ce611",
            "0df020eae3de454384138a355b0612bf",
            "87e86c7926dc4bdf84a050186cde31bd",
            "05000d582ffb4da8b6d5666486c6d2ef",
            "dbbeb636bd784267b42ce3b738a3f15c",
            "54f2bc095ea0490a83c7606cd167ffb5",
            "61b108221d5e4916af7637342c925d19",
            "df12c3f6cd7c4a9087e694bd0498bc11",
            "a36807101c3948759794c9ed63e60468",
            "9c181b1112ac4892a3c324859b514f97",
            "cd915704a2944e95b454cc8bca9524e1"
          ]
        },
        "id": "W3bw3MmqwjWN",
        "outputId": "2fbaa77b-e821-4aa1-f8ca-6c0eefce475a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "438c973005dd4b8d852bcd3a186ce611",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model initialized with 138567970 parameters\n",
            "Tag-Intent Classifier: Biaffine\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# 7) MODEL INITIALIZATION\n",
        "# ================================\n",
        "\n",
        "NUM_SLOTS = len(SLOT_LABELS)\n",
        "NUM_INTENTS = len(INTENT_LABELS)\n",
        "NUM_TOKEN_INTENTS = len(TOKEN_INTENT_LABELS)\n",
        "NUM_TAG_INTENTS = len(INTENT_LABELS_WITH_PAD)\n",
        "\n",
        "model = VSLIM(\n",
        "    model_name=MODEL_NAME,\n",
        "    num_slots=NUM_SLOTS,\n",
        "    num_intents=NUM_INTENTS,\n",
        "    num_token_intents=NUM_TOKEN_INTENTS,\n",
        "    num_tag_intents=NUM_TAG_INTENTS,\n",
        "    dropout=0.1,\n",
        "    use_crf=False,\n",
        "    num_mask=NUM_MASK,\n",
        "    cls_token_cat=True,\n",
        "    intent_attn=True,\n",
        "    use_biaffine_tag_intent=True\n",
        ")\n",
        "\n",
        "model.to(DEVICE)\n",
        "print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")\n",
        "print(f\"Tag-Intent Classifier: {'Biaffine' if model.use_biaffine_tag_intent else 'Linear'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiT1INi9zOXN",
        "outputId": "1f0d0926-23cd-4f88-a24d-017bf6000b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUGGING MASK SHAPES...\n",
            "sequence_output shape: [batch, seq_len, hidden]\n",
            "BI_tag_mask shape: torch.Size([32, 4, 128])\n",
            "B_tag_mask shape: torch.Size([32, 4, 128])\n",
            "Expected: BI_tag_mask should be [batch, num_mask, seq_len]\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Thêm vào trước training loop\n",
        "print(\"DEBUGGING MASK SHAPES...\")\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(f\"sequence_output shape: [batch, seq_len, hidden]\")\n",
        "print(f\"BI_tag_mask shape: {sample_batch['BI_tag_mask'].shape}\")\n",
        "print(f\"B_tag_mask shape: {sample_batch['B_tag_mask'].shape}\")\n",
        "print(f\"Expected: BI_tag_mask should be [batch, num_mask, seq_len]\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqzjretXwrq-",
        "outputId": "4b76f06e-6415-4b51-9507-9beec38107ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Total epochs: 50\n",
            "Batch size: 32\n",
            "Learning rate: 5e-05\n",
            "Loss weights: slot=2.0, tokint=2.0, uttint=1.0, tagint=1.0\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch  1/50\n",
            "  Train: total=14.7967 (intent=0.9514, slot=2.7085, tokint=1.7886, tagint=4.8512)\n",
            "  Val:   total=16.0348 (intent=0.5399, slot=2.5449, tokint=1.7386, tagint=6.9278)\n",
            "Epoch  2/50\n",
            "  Train: total=13.0566 (intent=0.6526, slot=2.2734, tokint=1.6473, tagint=4.5625)\n",
            "  Val:   total=14.3438 (intent=0.3798, slot=2.0787, tokint=1.5985, tagint=6.6097)\n",
            "Epoch  3/50\n",
            "  Train: total=11.5140 (intent=0.4876, slot=1.9479, tokint=1.4692, tagint=4.1920)\n",
            "  Val:   total=12.9730 (intent=0.2746, slot=1.8386, tokint=1.3289, tagint=6.3633)\n",
            "Epoch  4/50\n",
            "  Train: total=9.7321 (intent=0.3245, slot=1.7532, tokint=1.0622, tagint=3.7769)\n",
            "  Val:   total=11.2391 (intent=0.1547, slot=1.6148, tokint=0.7981, tagint=6.2586)\n",
            "Epoch  5/50\n",
            "  Train: total=7.9427 (intent=0.2442, slot=1.4834, tokint=0.5680, tagint=3.5955)\n",
            "  Val:   total=9.7210 (intent=0.1520, slot=1.2851, tokint=0.4514, tagint=6.0959)\n",
            "Epoch  6/50\n",
            "  Train: total=6.7092 (intent=0.1499, slot=1.1909, tokint=0.3308, tagint=3.5158)\n",
            "  Val:   total=8.9576 (intent=0.1143, slot=1.0160, tokint=0.3423, tagint=6.1266)\n",
            "Epoch  7/50\n",
            "  Train: total=5.7590 (intent=0.0808, slot=0.8725, tokint=0.2335, tagint=3.4662)\n",
            "  Val:   total=8.1417 (intent=0.0709, slot=0.7305, tokint=0.2706, tagint=6.0688)\n",
            "Epoch  8/50\n",
            "  Train: total=5.0242 (intent=0.0441, slot=0.5863, tokint=0.1747, tagint=3.4581)\n",
            "  Val:   total=7.7377 (intent=0.0969, slot=0.5038, tokint=0.2676, tagint=6.0980)\n",
            "Epoch  9/50\n",
            "  Train: total=4.5427 (intent=0.0287, slot=0.3860, tokint=0.1430, tagint=3.4559)\n",
            "  Val:   total=7.5484 (intent=0.0965, slot=0.4169, tokint=0.2529, tagint=6.1123)\n",
            "Epoch 10/50\n",
            "  Train: total=4.2946 (intent=0.0263, slot=0.2879, tokint=0.1187, tagint=3.4552)\n",
            "  Val:   total=7.1316 (intent=0.0795, slot=0.3407, tokint=0.1700, tagint=6.0306)\n",
            "Epoch 11/50\n",
            "  Train: total=4.1139 (intent=0.0250, slot=0.2273, tokint=0.1024, tagint=3.4296)\n",
            "  Val:   total=7.0184 (intent=0.0669, slot=0.3011, tokint=0.1673, tagint=6.0146)\n",
            "Epoch 12/50\n",
            "  Train: total=3.9767 (intent=0.0170, slot=0.1777, tokint=0.0829, tagint=3.4384)\n",
            "  Val:   total=7.3151 (intent=0.1004, slot=0.2859, tokint=0.2112, tagint=6.2206)\n",
            "Epoch 13/50\n",
            "  Train: total=3.9054 (intent=0.0167, slot=0.1462, tokint=0.0722, tagint=3.4518)\n",
            "  Val:   total=7.0438 (intent=0.0760, slot=0.2670, tokint=0.1826, tagint=6.0685)\n",
            "Epoch 14/50\n",
            "  Train: total=3.8057 (intent=0.0139, slot=0.1181, tokint=0.0616, tagint=3.4323)\n",
            "  Val:   total=7.0085 (intent=0.0934, slot=0.2465, tokint=0.1694, tagint=6.0832)\n",
            "Epoch 15/50\n",
            "  Train: total=3.7667 (intent=0.0144, slot=0.1025, tokint=0.0531, tagint=3.4411)\n",
            "  Val:   total=7.1966 (intent=0.1079, slot=0.2578, tokint=0.2123, tagint=6.1485)\n",
            "Epoch 16/50\n",
            "  Train: total=3.7134 (intent=0.0094, slot=0.0878, tokint=0.0457, tagint=3.4371)\n",
            "  Val:   total=7.1500 (intent=0.1051, slot=0.2382, tokint=0.2111, tagint=6.1462)\n",
            "Epoch 17/50\n",
            "  Train: total=3.6868 (intent=0.0113, slot=0.0744, tokint=0.0403, tagint=3.4461)\n",
            "  Val:   total=7.1679 (intent=0.2563, slot=0.2229, tokint=0.1757, tagint=6.1145)\n",
            "Epoch 18/50\n",
            "  Train: total=3.6677 (intent=0.0128, slot=0.0693, tokint=0.0369, tagint=3.4424)\n",
            "  Val:   total=7.2319 (intent=0.3288, slot=0.2242, tokint=0.1791, tagint=6.0965)\n",
            "Epoch 19/50\n",
            "  Train: total=3.6248 (intent=0.0086, slot=0.0577, tokint=0.0351, tagint=3.4307)\n",
            "  Val:   total=7.3909 (intent=0.4094, slot=0.2271, tokint=0.1941, tagint=6.1390)\n",
            "Epoch 20/50\n",
            "  Train: total=3.5963 (intent=0.0111, slot=0.0471, tokint=0.0306, tagint=3.4298)\n",
            "  Val:   total=6.8353 (intent=0.0897, slot=0.1922, tokint=0.1428, tagint=6.0757)\n",
            "Epoch 21/50\n",
            "  Train: total=3.5879 (intent=0.0050, slot=0.0422, tokint=0.0267, tagint=3.4452)\n",
            "  Val:   total=6.9624 (intent=0.1464, slot=0.1960, tokint=0.1652, tagint=6.0936)\n",
            "Epoch 22/50\n",
            "  Train: total=3.5630 (intent=0.0092, slot=0.0393, tokint=0.0217, tagint=3.4319)\n",
            "  Val:   total=7.1423 (intent=0.1973, slot=0.2056, tokint=0.2043, tagint=6.1251)\n",
            "Epoch 23/50\n",
            "  Train: total=3.5432 (intent=0.0043, slot=0.0342, tokint=0.0194, tagint=3.4318)\n",
            "  Val:   total=7.1322 (intent=0.2634, slot=0.1890, tokint=0.1747, tagint=6.1414)\n",
            "Epoch 24/50\n",
            "  Train: total=3.5465 (intent=0.0119, slot=0.0306, tokint=0.0183, tagint=3.4368)\n",
            "  Val:   total=7.2825 (intent=0.2074, slot=0.2128, tokint=0.2180, tagint=6.2135)\n",
            "Epoch 25/50\n",
            "  Train: total=3.5417 (intent=0.0067, slot=0.0263, tokint=0.0159, tagint=3.4505)\n",
            "  Val:   total=7.1343 (intent=0.1908, slot=0.2005, tokint=0.1926, tagint=6.1574)\n",
            "Epoch 26/50\n",
            "  Train: total=3.5201 (intent=0.0055, slot=0.0241, tokint=0.0135, tagint=3.4394)\n",
            "  Val:   total=7.2126 (intent=0.2129, slot=0.2111, tokint=0.2091, tagint=6.1593)\n",
            "Epoch 27/50\n",
            "  Train: total=3.5235 (intent=0.0030, slot=0.0227, tokint=0.0139, tagint=3.4473)\n",
            "  Val:   total=7.2996 (intent=0.3518, slot=0.1963, tokint=0.2146, tagint=6.1260)\n",
            "Epoch 28/50\n",
            "  Train: total=3.5091 (intent=0.0071, slot=0.0192, tokint=0.0133, tagint=3.4368)\n",
            "  Val:   total=7.5087 (intent=0.4131, slot=0.2263, tokint=0.2433, tagint=6.1563)\n",
            "Epoch 29/50\n",
            "  Train: total=3.5034 (intent=0.0044, slot=0.0188, tokint=0.0108, tagint=3.4396)\n",
            "  Val:   total=7.5424 (intent=0.2318, slot=0.2477, tokint=0.2885, tagint=6.2382)\n",
            "Epoch 30/50\n",
            "  Train: total=3.5033 (intent=0.0058, slot=0.0168, tokint=0.0110, tagint=3.4420)\n",
            "  Val:   total=7.2860 (intent=0.2743, slot=0.2073, tokint=0.2101, tagint=6.1769)\n",
            "Epoch 31/50\n",
            "  Train: total=3.4832 (intent=0.0021, slot=0.0161, tokint=0.0099, tagint=3.4292)\n",
            "  Val:   total=6.9159 (intent=0.1913, slot=0.1728, tokint=0.1562, tagint=6.0667)\n",
            "Epoch 32/50\n",
            "  Train: total=3.5025 (intent=0.0018, slot=0.0168, tokint=0.0100, tagint=3.4471)\n",
            "  Val:   total=6.7661 (intent=0.1959, slot=0.1470, tokint=0.1126, tagint=6.0509)\n",
            "Epoch 33/50\n",
            "  Train: total=3.4693 (intent=0.0019, slot=0.0147, tokint=0.0082, tagint=3.4215)\n",
            "  Val:   total=7.0528 (intent=0.2784, slot=0.1841, tokint=0.1639, tagint=6.0785)\n",
            "Epoch 34/50\n",
            "  Train: total=3.4789 (intent=0.0011, slot=0.0133, tokint=0.0083, tagint=3.4346)\n",
            "  Val:   total=7.1459 (intent=0.2051, slot=0.2054, tokint=0.2031, tagint=6.1237)\n",
            "Epoch 35/50\n",
            "  Train: total=3.4665 (intent=0.0037, slot=0.0131, tokint=0.0075, tagint=3.4216)\n",
            "  Val:   total=7.1860 (intent=0.2689, slot=0.2083, tokint=0.1919, tagint=6.1166)\n",
            "Epoch 36/50\n",
            "  Train: total=3.4610 (intent=0.0030, slot=0.0125, tokint=0.0070, tagint=3.4189)\n",
            "  Val:   total=7.2311 (intent=0.3480, slot=0.2095, tokint=0.1883, tagint=6.0876)\n",
            "Epoch 37/50\n",
            "  Train: total=3.4916 (intent=0.0008, slot=0.0126, tokint=0.0067, tagint=3.4522)\n",
            "  Val:   total=7.3090 (intent=0.3418, slot=0.2166, tokint=0.2060, tagint=6.1220)\n",
            "Epoch 38/50\n",
            "  Train: total=3.4601 (intent=0.0010, slot=0.0109, tokint=0.0066, tagint=3.4241)\n",
            "  Val:   total=7.2447 (intent=0.2715, slot=0.2166, tokint=0.2094, tagint=6.1212)\n",
            "Epoch 39/50\n",
            "  Train: total=3.4691 (intent=0.0002, slot=0.0109, tokint=0.0065, tagint=3.4343)\n",
            "  Val:   total=7.1169 (intent=0.2669, slot=0.1962, tokint=0.1787, tagint=6.1003)\n",
            "Epoch 40/50\n",
            "  Train: total=3.4681 (intent=0.0007, slot=0.0101, tokint=0.0064, tagint=3.4343)\n",
            "  Val:   total=7.3255 (intent=0.3487, slot=0.2136, tokint=0.2075, tagint=6.1347)\n",
            "Epoch 41/50\n",
            "  Train: total=3.4567 (intent=0.0010, slot=0.0099, tokint=0.0059, tagint=3.4240)\n",
            "  Val:   total=7.2101 (intent=0.3418, slot=0.2052, tokint=0.1867, tagint=6.0846)\n",
            "Epoch 42/50\n",
            "  Train: total=3.4552 (intent=0.0006, slot=0.0095, tokint=0.0057, tagint=3.4240)\n",
            "  Val:   total=7.1890 (intent=0.2722, slot=0.2111, tokint=0.1947, tagint=6.1051)\n",
            "Epoch 43/50\n",
            "  Train: total=3.4533 (intent=0.0007, slot=0.0098, tokint=0.0058, tagint=3.4215)\n",
            "  Val:   total=7.1740 (intent=0.2706, slot=0.2108, tokint=0.1932, tagint=6.0954)\n",
            "Epoch 44/50\n",
            "  Train: total=3.4713 (intent=0.0001, slot=0.0092, tokint=0.0054, tagint=3.4420)\n",
            "  Val:   total=7.3273 (intent=0.3518, slot=0.2190, tokint=0.2107, tagint=6.1161)\n",
            "Epoch 45/50\n",
            "  Train: total=3.4555 (intent=0.0002, slot=0.0090, tokint=0.0054, tagint=3.4266)\n",
            "  Val:   total=7.4006 (intent=0.3559, slot=0.2262, tokint=0.2277, tagint=6.1369)\n",
            "Epoch 46/50\n",
            "  Train: total=3.4827 (intent=0.0002, slot=0.0085, tokint=0.0054, tagint=3.4547)\n",
            "  Val:   total=7.3823 (intent=0.3524, slot=0.2232, tokint=0.2253, tagint=6.1329)\n",
            "Epoch 47/50\n",
            "  Train: total=3.4468 (intent=0.0001, slot=0.0088, tokint=0.0051, tagint=3.4189)\n",
            "  Val:   total=7.4056 (intent=0.3557, slot=0.2239, tokint=0.2300, tagint=6.1420)\n",
            "Epoch 48/50\n",
            "  Train: total=3.4367 (intent=0.0001, slot=0.0087, tokint=0.0052, tagint=3.4087)\n",
            "  Val:   total=7.3296 (intent=0.2837, slot=0.2223, tokint=0.2299, tagint=6.1413)\n",
            "Epoch 49/50\n",
            "  Train: total=3.4601 (intent=0.0013, slot=0.0084, tokint=0.0051, tagint=3.4317)\n",
            "  Val:   total=7.3907 (intent=0.3557, slot=0.2216, tokint=0.2279, tagint=6.1361)\n",
            "Epoch 50/50\n",
            "  Train: total=3.4641 (intent=0.0001, slot=0.0083, tokint=0.0052, tagint=3.4368)\n",
            "  Val:   total=7.3806 (intent=0.3546, slot=0.2206, tokint=0.2258, tagint=6.1332)\n",
            "Best model loaded for inference and evaluation.\n"
          ]
        }
      ],
      "source": [
        "# =================\n",
        "# 8) TRAINING LOOP \n",
        "# =================\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "        'weight_decay': WEIGHT_DECAY\n",
        "    },\n",
        "    {\n",
        "        'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "        'weight_decay': 0.0\n",
        "    }\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=LR, eps=1e-8)\n",
        "\n",
        "total_steps = len(train_loader) * EPOCHS\n",
        "warmup_steps = int(0.1 * total_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "def train_epoch():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_intent_loss = 0\n",
        "    total_slot_loss = 0\n",
        "    total_tokint_loss = 0\n",
        "    total_tagint_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Move to device\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "            token_type_ids=batch[\"token_type_ids\"],\n",
        "            intent_label_ids=batch[\"uttint_labels\"],\n",
        "            slot_labels_ids=batch[\"slot_labels\"],\n",
        "            intent_token_ids=batch[\"tokint_labels\"],\n",
        "            B_tag_mask=batch[\"B_tag_mask\"],\n",
        "            BI_tag_mask=batch[\"BI_tag_mask\"],\n",
        "            tag_intent_label=batch[\"tag_intent_label\"]\n",
        "        )\n",
        "\n",
        "        # Backward pass\n",
        "        outputs[\"total_loss\"].backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Accumulate losses\n",
        "        total_loss += outputs[\"total_loss\"].item()\n",
        "        total_intent_loss += outputs[\"intent_loss\"]\n",
        "        total_slot_loss += outputs[\"slot_loss\"]\n",
        "        total_tokint_loss += outputs[\"intent_token_loss\"]\n",
        "        total_tagint_loss += outputs[\"tag_intent_loss\"]\n",
        "\n",
        "    return (\n",
        "        total_loss / len(train_loader),\n",
        "        total_intent_loss / len(train_loader),\n",
        "        total_slot_loss / len(train_loader),\n",
        "        total_tokint_loss / len(train_loader),\n",
        "        total_tagint_loss / len(train_loader)\n",
        "    )\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate():\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_intent_loss = 0\n",
        "    total_slot_loss = 0\n",
        "    total_tokint_loss = 0\n",
        "    total_tagint_loss = 0\n",
        "\n",
        "    for batch in val_loader:\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "            token_type_ids=batch[\"token_type_ids\"],\n",
        "            intent_label_ids=batch[\"uttint_labels\"],\n",
        "            slot_labels_ids=batch[\"slot_labels\"],\n",
        "            intent_token_ids=batch[\"tokint_labels\"],\n",
        "            B_tag_mask=batch[\"B_tag_mask\"],\n",
        "            BI_tag_mask=batch[\"BI_tag_mask\"],\n",
        "            tag_intent_label=batch[\"tag_intent_label\"]\n",
        "        )\n",
        "\n",
        "        total_loss += outputs[\"total_loss\"].item()\n",
        "        total_intent_loss += outputs[\"intent_loss\"]\n",
        "        total_slot_loss += outputs[\"slot_loss\"]\n",
        "        total_tokint_loss += outputs[\"intent_token_loss\"]\n",
        "        total_tagint_loss += outputs[\"tag_intent_loss\"]\n",
        "\n",
        "    return (\n",
        "        total_loss / len(val_loader),\n",
        "        total_intent_loss / len(val_loader),\n",
        "        total_slot_loss / len(val_loader),\n",
        "        total_tokint_loss / len(val_loader),\n",
        "        total_tagint_loss / len(val_loader)\n",
        "    )\n",
        "\n",
        "# Training loop\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "patience = 5\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(f\"Total epochs: {EPOCHS}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Learning rate: {LR}\")\n",
        "print(f\"Loss weights: slot={W_SLOT}, tokint={W_TOKINTENT}, uttint={W_UTTINTENT}, tagint={W_TAGINTENT}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Train\n",
        "    train_loss, train_intent, train_slot, train_tokint, train_tagint = train_epoch()\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_intent, val_slot, val_tokint, val_tagint = validate()\n",
        "\n",
        "    # Save losses\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"Epoch {epoch+1:2d}/{EPOCHS}\")\n",
        "    print(f\"  Train: total={train_loss:.4f} (intent={train_intent:.4f}, slot={train_slot:.4f}, tokint={train_tokint:.4f}, tagint={train_tagint:.4f})\")\n",
        "    print(f\"  Val:   total={val_loss:.4f} (intent={val_intent:.4f}, slot={val_slot:.4f}, tokint={val_tokint:.4f}, tagint={val_tagint:.4f})\")\n",
        "\n",
        "#     # Early stopping\n",
        "#     if val_loss < best_val_loss - 1e-4:\n",
        "#         best_val_loss = val_loss\n",
        "#         patience_counter = 0\n",
        "#         torch.save(model.state_dict(), \"slim_full_best_model.pt\")\n",
        "#         print(\"  ✓ New best model saved!\")\n",
        "#     else:\n",
        "#         patience_counter += 1\n",
        "#         print(f\"  No improvement ({patience_counter}/{patience})\")\n",
        "\n",
        "#     if patience_counter >= patience:\n",
        "#         print(\"  Early stopping triggered!\")\n",
        "#         break\n",
        "\n",
        "#     print()\n",
        "\n",
        "# # Load best model\n",
        "# model.load_state_dict(torch.load(\"slim_full_best_model.pt\", map_location=DEVICE))\n",
        "print(\"Best model loaded for inference and evaluation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "mRusvhAzwsW7",
        "outputId": "a54bafeb-b6f4-445b-f5a2-0878e6402b39"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completed in 50 epochs\n",
            "Best validation loss: inf\n"
          ]
        }
      ],
      "source": [
        "# Plot training curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(train_losses) + 1), train_losses, 'b-', label='Train Loss', marker='o')\n",
        "plt.plot(range(1, len(val_losses) + 1), val_losses, 'r-', label='Validation Loss', marker='s')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('VSLIM Training Progress')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Training completed in {len(train_losses)} epochs\")\n",
        "print(f\"Best validation loss: {best_val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "H3apXHQkxIdy"
      },
      "outputs": [],
      "source": [
        "# ====================\n",
        "# 9) EVALUATION MODULE\n",
        "# ====================\n",
        "\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score as seq_f1\n",
        "from seqeval.metrics.sequence_labeling import get_entities\n",
        "\n",
        "# ============= HELPER FUNCTIONS =============\n",
        "\n",
        "def getEntities(elems):\n",
        "    \"\"\"\n",
        "    Compress the entities\n",
        "    For example: ['O', 'Good', 'Good', 'O', 'O']\n",
        "                 will be compressed as [('O', 0, 1), ('Good', 1, 3), ('O', 3, 5)]\n",
        "    \"\"\"\n",
        "    if isinstance(elems[0], list):\n",
        "        elems = [item for sub in elems for item in sub + ['O']]\n",
        "\n",
        "    current_char = elems[0]\n",
        "    elem_len = len(elems)\n",
        "    current_idx = 0\n",
        "    ptr = current_idx + 1\n",
        "    entities = []\n",
        "\n",
        "    while ptr < elem_len:\n",
        "        if ptr == elem_len - 1:\n",
        "            if elems[ptr] == current_char:\n",
        "                entities.append((current_char, current_idx, ptr + 1))\n",
        "            else:\n",
        "                entities.append((current_char, current_idx, ptr))\n",
        "                entities.append((elems[ptr], ptr, ptr+1))\n",
        "            break\n",
        "\n",
        "        if elems[ptr] != current_char:\n",
        "            entities.append((current_char, current_idx, ptr))\n",
        "            current_idx = ptr\n",
        "            current_char = elems[ptr]\n",
        "\n",
        "        ptr += 1\n",
        "\n",
        "    return entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Y2eAV1_CqafP"
      },
      "outputs": [],
      "source": [
        "# ============= METRICS FUNCTIONS =============\n",
        "def get_slot_metrics(preds, labels):\n",
        "    \"\"\"utils.py line 125-131\"\"\"\n",
        "    assert len(preds) == len(labels)\n",
        "    return {\n",
        "        \"slot_precision\": precision_score(labels, preds),\n",
        "        \"slot_recall\": recall_score(labels, preds),\n",
        "        \"slot_f1\": seq_f1(labels, preds)\n",
        "    }\n",
        "\n",
        "def get_multi_intent_acc(intent_preds, intent_labels):\n",
        "    \"\"\"utils.py line 141-155\"\"\"\n",
        "    intent_preds = intent_preds.tolist() if torch.is_tensor(intent_preds) else intent_preds.tolist()\n",
        "    intent_labels = intent_labels.tolist() if torch.is_tensor(intent_labels) else intent_labels.tolist()\n",
        "    records = []\n",
        "    for ip, il in zip(intent_preds, intent_labels):\n",
        "        one_sent = True\n",
        "        for ipn, iln in zip(ip, il):\n",
        "            if ipn != iln:\n",
        "                one_sent = False\n",
        "                break\n",
        "        records.append(int(one_sent))\n",
        "\n",
        "    return {\n",
        "        \"intent_acc\": np.mean(records)\n",
        "    }\n",
        "\n",
        "def get_intent_token_metrics(intent_token_preds, intent_tokens):\n",
        "    \"\"\"utils.py line 220-245\"\"\"\n",
        "    pred_tokens = set([item for item in getEntities(intent_token_preds) if item[0] != 'O'])\n",
        "    true_tokens = set([item for item in getEntities(intent_tokens) if item[0] != 'O'])\n",
        "\n",
        "    nb_correct = len(pred_tokens & true_tokens)\n",
        "    nb_pred = len(pred_tokens)\n",
        "    nb_true = len(true_tokens)\n",
        "\n",
        "    pre = nb_correct / nb_pred if nb_pred > 0 else 0\n",
        "    recall = nb_correct / nb_true if nb_true > 0 else 0\n",
        "    score = 2 * pre * recall / (pre + recall) if pre + recall > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'intent_token_precision': pre,\n",
        "        'intent_token_recall': recall,\n",
        "        'intent_token_f1': score,\n",
        "    }\n",
        "\n",
        "def get_tag_intent_metrics_fixed(tag_intent_preds, tag_intent_ids):\n",
        "    \"\"\"\n",
        "    So sánh tag-intent CHỈ Ở VỊ TRÍ NON-PAD trong ground truth\n",
        "    \"\"\"\n",
        "    total_cnt = 0\n",
        "    correct_cnt = 0\n",
        "\n",
        "    for pred_list, gt_list in zip(tag_intent_preds, tag_intent_ids):\n",
        "        for pred, gt in zip(pred_list, gt_list):\n",
        "            # CHỈ tính những vị trí có ground truth label (không phải PAD)\n",
        "            if gt != \"PAD\":\n",
        "                if pred == gt:\n",
        "                    correct_cnt += 1\n",
        "                total_cnt += 1\n",
        "\n",
        "    return {\n",
        "        'tag_intent_acc': correct_cnt / total_cnt if total_cnt > 0 else 0\n",
        "    }\n",
        "\n",
        "def get_semantic_basic_acc(intent_preds, intent_labels, slot_preds, slot_labels):\n",
        "    \"\"\"\n",
        "    Semantic Basic Accuracy - CHỈ so sánh intent + slot\n",
        "    (Không tính token-intent và tag-intent)\n",
        "    \"\"\"\n",
        "    intent_preds = intent_preds.tolist() if torch.is_tensor(intent_preds) else intent_preds.tolist()\n",
        "    intent_labels = intent_labels.tolist() if torch.is_tensor(intent_labels) else intent_labels.tolist()\n",
        "\n",
        "    correct = 0\n",
        "    total = len(intent_labels)\n",
        "\n",
        "    for intent_pred, intent_label, slot_pred, slot_label in zip(\n",
        "        intent_preds, intent_labels, slot_preds, slot_labels\n",
        "    ):\n",
        "        # Intent match (multi-hot comparison)\n",
        "        intent_match = all(ip == il for ip, il in zip(intent_pred, intent_label))\n",
        "\n",
        "        # Slot match (sequence comparison)\n",
        "        slot_match = (slot_pred == slot_label)\n",
        "\n",
        "        if intent_match and slot_match:\n",
        "            correct += 1\n",
        "\n",
        "    return {\n",
        "        \"semantic_basic_acc\": correct / total if total > 0 else 0\n",
        "    }\n",
        "\n",
        "def get_sentence_frame_acc_multi_intent_fixed(intent_preds,\n",
        "                                        intent_labels,\n",
        "                                        slot_preds,\n",
        "                                        slot_labels,\n",
        "                                        intent_token_preds=None,\n",
        "                                        intent_tokens=None,\n",
        "                                        tag_intent_preds=None,\n",
        "                                        tag_intent_labels=None):\n",
        "    \"\"\"\n",
        "    FIX: CHỈ so sánh tag-intent ở vị trí NON-PAD\n",
        "    \"\"\"\n",
        "    intent_token_existence = (intent_token_preds is not None and intent_tokens is not None)\n",
        "    tag_intent_existence = (tag_intent_preds is not None and tag_intent_labels is not None)\n",
        "\n",
        "    # Intent comparison\n",
        "    intent_result = []\n",
        "    intent_preds = intent_preds.tolist() if torch.is_tensor(intent_preds) else intent_preds.tolist()\n",
        "    intent_labels = intent_labels.tolist() if torch.is_tensor(intent_labels) else intent_labels.tolist()\n",
        "\n",
        "    for ip, il in zip(intent_preds, intent_labels):\n",
        "        one_sent = True\n",
        "        for ipn, iln in zip(ip, il):\n",
        "            if ipn != iln:\n",
        "                one_sent = False\n",
        "                break\n",
        "        intent_result.append(int(one_sent))\n",
        "    intent_result = np.array(intent_result)\n",
        "\n",
        "    # Slot comparison\n",
        "    slot_result = []\n",
        "    for preds, labels in zip(slot_preds, slot_labels):\n",
        "        assert len(preds) == len(labels)\n",
        "        one_sent_result = True\n",
        "        for p, l in zip(preds, labels):\n",
        "            if p != l:\n",
        "                one_sent_result = False\n",
        "                break\n",
        "        slot_result.append(one_sent_result)\n",
        "\n",
        "    slot_result = np.array(slot_result)\n",
        "\n",
        "    # Intent token comparison\n",
        "    if intent_token_existence:\n",
        "        intent_token_result = []\n",
        "        for preds, labels in zip(intent_token_preds, intent_tokens):\n",
        "            assert len(preds) == len(labels)\n",
        "            one_sent_result = True\n",
        "            for p, l in zip(preds, labels):\n",
        "                if p != l:\n",
        "                    one_sent_result = False\n",
        "                    break\n",
        "            intent_token_result.append(one_sent_result)\n",
        "\n",
        "        intent_token_result = np.array(intent_token_result)\n",
        "\n",
        "    # Tag-intent comparison - FIX: CHỈ so sánh NON-PAD\n",
        "    if tag_intent_existence:\n",
        "        tag_intent_result = []\n",
        "        for preds, labels in zip(tag_intent_preds, tag_intent_labels):\n",
        "            one_sent_result = True\n",
        "            for p, l in zip(preds, labels):\n",
        "                # CHỈ so sánh khi ground truth không phải PAD\n",
        "                if l != \"PAD\":\n",
        "                    if p != l:\n",
        "                        one_sent_result = False\n",
        "                        break\n",
        "            tag_intent_result.append(one_sent_result)\n",
        "\n",
        "        tag_intent_result = np.array(tag_intent_result)\n",
        "\n",
        "    # Combine all results\n",
        "    if tag_intent_existence and intent_token_existence:\n",
        "        sementic_acc = np.multiply(np.multiply(np.multiply(intent_result, slot_result), intent_token_result), tag_intent_result).mean()\n",
        "    elif tag_intent_existence:\n",
        "        sementic_acc = np.multiply(np.multiply(intent_result, slot_result), tag_intent_result).mean()\n",
        "    elif intent_token_existence:\n",
        "        sementic_acc = np.multiply(np.multiply(intent_result, slot_result), intent_token_result).mean()\n",
        "    else:\n",
        "        sementic_acc = np.multiply(intent_result, slot_result).mean()\n",
        "\n",
        "    intent_slot_acc = np.multiply(intent_result, slot_result).mean()\n",
        "    return {\n",
        "        \"sementic_frame_acc\": sementic_acc,\n",
        "        \"intent_slot_acc\": intent_slot_acc,\n",
        "    }\n",
        "\n",
        "def compute_metrics_multi_intent_fixed(intent_preds,\n",
        "                                 intent_labels,\n",
        "                                 slot_preds,\n",
        "                                 slot_labels,\n",
        "                                 intent_token_preds=None,\n",
        "                                 intent_tokens=None,\n",
        "                                 tag_intent_preds=None,\n",
        "                                 tag_intent_ids=None):\n",
        "    \"\"\"FIX: Dùng hàm fixed\"\"\"\n",
        "    intent_seq_existence = (intent_token_preds is not None and intent_tokens is not None)\n",
        "    tag_intent_existence = (tag_intent_preds is not None and tag_intent_ids is not None)\n",
        "\n",
        "    results = {}\n",
        "    intent_result = get_multi_intent_acc(intent_preds, intent_labels)\n",
        "    slot_result = get_slot_metrics(slot_preds, slot_labels)\n",
        "\n",
        "    if intent_seq_existence:\n",
        "        intent_token_result = get_intent_token_metrics(intent_token_preds, intent_tokens)\n",
        "\n",
        "    if tag_intent_existence:\n",
        "        tag_intent_result = get_tag_intent_metrics_fixed(tag_intent_preds, tag_intent_ids)  # FIX\n",
        "\n",
        "    sementic_result = get_sentence_frame_acc_multi_intent_fixed(  # FIX\n",
        "        intent_preds,\n",
        "        intent_labels,\n",
        "        slot_preds,\n",
        "        slot_labels,\n",
        "        intent_token_preds,\n",
        "        intent_tokens,\n",
        "        tag_intent_preds,\n",
        "        tag_intent_ids)\n",
        "\n",
        "    results.update(intent_result)\n",
        "    results.update(slot_result)\n",
        "    if intent_seq_existence:\n",
        "        results.update(intent_token_result)\n",
        "    if tag_intent_existence:\n",
        "        results.update(tag_intent_result)\n",
        "    results.update(sementic_result)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIRwYShGqafQ",
        "outputId": "e9853099-9602-4af3-f146-fe0ad848a143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VSLIM inference ready!\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# 10) VSLIM INFERENCE\n",
        "# ================================\n",
        "\n",
        "def align_tokens_for_inference(tokens: List[str], tokenizer, max_len=MAX_LEN):\n",
        "    \"\"\"Align pre-tokenized tokens to subwords for inference\"\"\"\n",
        "    subword_tokens = []\n",
        "    word_to_subword_map = []  # Maps word index to first subword index\n",
        "\n",
        "    for token in tokens:\n",
        "        word_to_subword_map.append(len(subword_tokens))\n",
        "        pieces = tokenizer.tokenize(token) or [tokenizer.unk_token]\n",
        "        subword_tokens.extend(pieces)\n",
        "\n",
        "    # Convert to input IDs with special tokens\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(subword_tokens)\n",
        "    input_ids = tokenizer.build_inputs_with_special_tokens(input_ids)\n",
        "\n",
        "    # Adjust mapping for special tokens (e.g., <s> at beginning)\n",
        "    word_to_subword_map = [idx + 1 for idx in word_to_subword_map]  # +1 for <s> token\n",
        "\n",
        "    attention_mask = [1] * len(input_ids)\n",
        "    token_type_ids = [0] * len(input_ids)\n",
        "\n",
        "    # Truncate if necessary\n",
        "    if len(input_ids) > max_len:\n",
        "        input_ids = input_ids[:max_len]\n",
        "        attention_mask = attention_mask[:max_len]\n",
        "        token_type_ids = token_type_ids[:max_len]\n",
        "        # Filter out word mappings that point beyond max_len\n",
        "        word_to_subword_map = [idx for idx in word_to_subword_map if idx < max_len]\n",
        "\n",
        "    # Pad to max_len\n",
        "    pad_len = max_len - len(input_ids)\n",
        "    if pad_len > 0:\n",
        "        pad_id = tokenizer.pad_token_id\n",
        "        input_ids.extend([pad_id] * pad_len)\n",
        "        attention_mask.extend([0] * pad_len)\n",
        "        token_type_ids.extend([0] * pad_len)\n",
        "\n",
        "    return (\n",
        "        torch.tensor(input_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "        torch.tensor(attention_mask, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "        torch.tensor(token_type_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "        word_to_subword_map\n",
        "    )\n",
        "\n",
        "def predict_full_slim(tokens: List[str], threshold: float = UTT_THRESHOLD) -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Full SLIM inference with all paper features\n",
        "\n",
        "    Args:\n",
        "        tokens: Pre-tokenized input tokens\n",
        "        threshold: Threshold for utterance intent classification\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with utterance_intents, slot_tags, token_intents\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Prepare input\n",
        "        input_ids, attention_mask, token_type_ids, word_positions = align_tokens_for_inference(tokens, tokenizer)\n",
        "\n",
        "        # Create dummy B/BI masks for inference (all zeros since we don't have ground truth)\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "        B_tag_mask = torch.zeros(batch_size, NUM_MASK, seq_len, dtype=torch.long, device=DEVICE)\n",
        "        BI_tag_mask = torch.zeros(batch_size, NUM_MASK, seq_len, dtype=torch.float, device=DEVICE)\n",
        "        tag_intent_label = torch.full((batch_size, NUM_MASK), IGNORE_INDEX, dtype=torch.long, device=DEVICE)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            intent_label_ids=None,  # No ground truth for inference\n",
        "            slot_labels_ids=None,\n",
        "            intent_token_ids=None,\n",
        "            B_tag_mask=B_tag_mask,\n",
        "            BI_tag_mask=BI_tag_mask,\n",
        "            tag_intent_label=tag_intent_label\n",
        "        )\n",
        "\n",
        "        # Extract logits\n",
        "        slot_logits = outputs[\"slot_logits\"][0]      # [seq_len, num_slots]\n",
        "        tokint_logits = outputs[\"intent_token_logits\"][0] if outputs[\"intent_token_logits\"] is not None else None  # [seq_len, num_tokints]\n",
        "        uttint_logits = outputs[\"intent_logits\"][0]  # [num_intents]\n",
        "\n",
        "        # === UTTERANCE INTENT PREDICTION ===\n",
        "        uttint_probs = uttint_logits.cpu().numpy()  # Already sigmoid from model\n",
        "        predicted_intents = []\n",
        "\n",
        "        # Apply threshold\n",
        "        for i, prob in enumerate(uttint_probs):\n",
        "            if prob >= threshold:\n",
        "                predicted_intents.append(INTENT_LABELS[i])\n",
        "\n",
        "        # Fallback: if no intent above threshold, take the highest\n",
        "        if not predicted_intents:\n",
        "            best_idx = np.argmax(uttint_probs)\n",
        "            predicted_intents = [INTENT_LABELS[best_idx]]\n",
        "\n",
        "        # === TOKEN-LEVEL PREDICTIONS ===\n",
        "        # Get predictions for each original word (first subword only)\n",
        "        slot_predictions = []\n",
        "        tokint_predictions = []\n",
        "\n",
        "        for word_idx, subword_pos in enumerate(word_positions):\n",
        "            if subword_pos >= slot_logits.size(0):\n",
        "                # Beyond sequence length, pad with \"O\"\n",
        "                slot_predictions.append(\"O\")\n",
        "                tokint_predictions.append(\"O\")\n",
        "                continue\n",
        "\n",
        "            # Slot prediction\n",
        "            slot_id = torch.argmax(slot_logits[subword_pos]).item()\n",
        "            slot_tag = ID2SLOT[slot_id]\n",
        "            slot_predictions.append(slot_tag)\n",
        "\n",
        "            # Token-intent prediction\n",
        "            if tokint_logits is not None:\n",
        "                if slot_tag == \"O\":\n",
        "                    tokint_predictions.append(\"O\")\n",
        "                else:\n",
        "                    tokint_id = torch.argmax(tokint_logits[subword_pos]).item()\n",
        "                    tokint_tag = ID2TOKINT[tokint_id]\n",
        "                    tokint_predictions.append(tokint_tag)\n",
        "            else:\n",
        "                tokint_predictions.append(\"O\")\n",
        "\n",
        "            # # ✅ Token-intent prediction (CORRECTED - độc lập với slots)\n",
        "            # if tokint_logits is not None:\n",
        "            #     tokint_id = torch.argmax(tokint_logits[subword_pos]).item()\n",
        "            #     tokint_tag = ID2TOKINT[tokint_id]\n",
        "            #     tokint_predictions.append(tokint_tag)\n",
        "            # else:\n",
        "            #     # Nếu model không output token-intent logits\n",
        "            #     tokint_predictions.append(\"O\")\n",
        "\n",
        "        # Ensure output length matches input length\n",
        "        num_tokens = len(tokens)\n",
        "        if len(slot_predictions) < num_tokens:\n",
        "            slot_predictions.extend([\"O\"] * (num_tokens - len(slot_predictions)))\n",
        "            tokint_predictions.extend([\"O\"] * (num_tokens - len(tokint_predictions)))\n",
        "        elif len(slot_predictions) > num_tokens:\n",
        "            slot_predictions = slot_predictions[:num_tokens]\n",
        "            tokint_predictions = tokint_predictions[:num_tokens]\n",
        "\n",
        "    return {\n",
        "        \"utterance_intents\": predicted_intents,\n",
        "        \"slot_tags\": slot_predictions,\n",
        "        \"token_intents\": tokint_predictions\n",
        "    }\n",
        "\n",
        "def show_prediction(tokens: List[str], prediction: Dict[str, List[str]]):\n",
        "    \"\"\"Display prediction in a readable format\"\"\"\n",
        "    print(\"Tokens:       \", \" \".join(tokens))\n",
        "    print(\"Utter intents:\", prediction[\"utterance_intents\"])\n",
        "    print(\"Slots:        \", \" \".join(prediction[\"slot_tags\"]))\n",
        "    print(\"Tok-intents:  \", \" \".join(prediction[\"token_intents\"]))\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "print(\"VSLIM inference ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gnb7r7vaqafQ",
        "outputId": "d6e46a80-a742-40d7-de8c-ba4630c88a28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 2-Pass Evaluation Module Ready (Y CHANG REPO GỐC)!\n"
          ]
        }
      ],
      "source": [
        "# ============= 2-PASS EVALUATION =============\n",
        "\n",
        "def generate_predicted_masks_from_slots(slot_preds_list, max_seq_len=MAX_LEN):\n",
        "    \"\"\"\n",
        "    Generate B AND BI masks from predicted slots\n",
        "    \"\"\"\n",
        "    B_tag_mask_pred = []\n",
        "    BI_tag_mask_pred = []\n",
        "\n",
        "    for i in range(len(slot_preds_list)):\n",
        "        entities = get_entities(slot_preds_list[i])\n",
        "        entities = [tag for tag in entities if slot_preds_list[i][tag[1]].startswith('B')]\n",
        "\n",
        "        if len(entities) > NUM_MASK:\n",
        "            entities = entities[:NUM_MASK]\n",
        "\n",
        "        # Initialize both masks\n",
        "        B_entity_masks = []\n",
        "        BI_entity_masks = []\n",
        "\n",
        "        for entity_idx, entity in enumerate(entities):\n",
        "            # B mask: only mark beginning\n",
        "            B_mask = [0 for _ in range(max_seq_len)]\n",
        "            start_idx = entity[1]\n",
        "            B_mask[start_idx] = 1\n",
        "            B_entity_masks.append(B_mask)\n",
        "\n",
        "            # BI mask: weighted span\n",
        "            BI_mask = [0.0 for _ in range(max_seq_len)]\n",
        "            end_idx = entity[2] + 1\n",
        "            weight = 1.0 / (end_idx - start_idx)\n",
        "            for pos in range(start_idx, end_idx):\n",
        "                if pos < len(slot_preds_list[i]):\n",
        "                    BI_mask[pos] = weight\n",
        "            BI_entity_masks.append(BI_mask)\n",
        "\n",
        "        # Pad to NUM_MASK\n",
        "        for extra_idx in range(NUM_MASK - len(B_entity_masks)):\n",
        "            B_entity_masks.append([0 for _ in range(max_seq_len)])\n",
        "            BI_entity_masks.append([0.0 for _ in range(max_seq_len)])\n",
        "\n",
        "        B_tag_mask_pred.append(B_entity_masks)\n",
        "        BI_tag_mask_pred.append(BI_entity_masks)\n",
        "\n",
        "    return torch.LongTensor(B_tag_mask_pred), torch.FloatTensor(BI_tag_mask_pred)\n",
        "\n",
        "def align_masks_to_subwords(masks, word_to_subword_map, max_len):\n",
        "    \"\"\"Align word-level masks to subword-level masks\"\"\"\n",
        "    num_masks = len(masks)\n",
        "    aligned_masks = torch.zeros(num_masks, max_len, dtype=torch.float)\n",
        "\n",
        "    for mask_idx in range(num_masks):\n",
        "        for word_idx, subword_idx in enumerate(word_to_subword_map):\n",
        "            if word_idx < len(masks[mask_idx]) and subword_idx < max_len:\n",
        "                aligned_masks[mask_idx, subword_idx] = masks[mask_idx][word_idx]\n",
        "\n",
        "    return aligned_masks\n",
        "\n",
        "def evaluate_2pass(mode='test'):\n",
        "    if mode == 'test':\n",
        "        dataset_sentences = load_data_with_masks(TEST_DIR)[0]\n",
        "        dataset_slots = load_data_with_masks(TEST_DIR)[1]\n",
        "        dataset_tokints = load_data_with_masks(TEST_DIR)[2]\n",
        "        dataset_intents = load_data_with_masks(TEST_DIR)[3]\n",
        "        dataset_tag_intents = load_data_with_masks(TEST_DIR)[6]\n",
        "    elif mode == 'dev':\n",
        "        dataset_sentences = dev_sentences\n",
        "        dataset_slots = dev_slot_tags\n",
        "        dataset_tokints = dev_token_intent_tags\n",
        "        dataset_intents = dev_utterance_intents\n",
        "        dataset_tag_intents = dev_tag_intent_labels\n",
        "    else:\n",
        "        raise ValueError(\"Mode must be 'test' or 'dev'\")\n",
        "\n",
        "    print(f\"***** Running evaluation on {mode} dataset *****\")\n",
        "    print(f\"  Num examples = {len(dataset_sentences)}\")\n",
        "\n",
        "    # ========== PASS 1: Predict intents and slots ==========\n",
        "    intent_preds = []\n",
        "    slot_preds = []\n",
        "    intent_token_preds = []\n",
        "    out_intent_label_ids = []\n",
        "    out_slot_labels_ids = []\n",
        "    out_intent_token_ids = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for tokens, slot_tags, tokint_tags, utt_intents in zip(\n",
        "        dataset_sentences, dataset_slots, dataset_tokints, dataset_intents):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            result = predict_full_slim(tokens)\n",
        "\n",
        "            # Intent predictions (multi-hot)\n",
        "            intent_multihot = [0] * len(INTENT_LABELS)\n",
        "            for intent in result[\"utterance_intents\"]:\n",
        "                if intent in INTENT2ID:\n",
        "                    intent_multihot[INTENT2ID[intent]] = 1\n",
        "            intent_preds.append(intent_multihot)\n",
        "\n",
        "            # Gold intent (multi-hot)\n",
        "            gold_multihot = [0] * len(INTENT_LABELS)\n",
        "            for intent in utt_intents:\n",
        "                if intent in INTENT2ID:\n",
        "                    gold_multihot[INTENT2ID[intent]] = 1\n",
        "            out_intent_label_ids.append(gold_multihot)\n",
        "\n",
        "            # Slot predictions\n",
        "            slot_preds.append(result[\"slot_tags\"])\n",
        "            out_slot_labels_ids.append(slot_tags)\n",
        "\n",
        "            # Token-intent predictions\n",
        "            intent_token_preds.append(result[\"token_intents\"])\n",
        "            out_intent_token_ids.append(tokint_tags)\n",
        "\n",
        "    # Convert to proper format\n",
        "    intent_preds = torch.as_tensor(intent_preds, dtype=torch.int32)\n",
        "    out_intent_label_ids = np.array(out_intent_label_ids)\n",
        "\n",
        "    # ========== Generate predicted masks ==========\n",
        "    slot_label_map = {i: label for i, label in enumerate(SLOT_LABELS)}\n",
        "    slot_preds_list = slot_preds  # Already in list format\n",
        "    out_slot_label_list = out_slot_labels_ids  # Already in list format\n",
        "\n",
        "    # Generate masks from predicted slots\n",
        "    B_tag_mask_pred_tensor, BI_tag_mask_pred_tensor = generate_predicted_masks_from_slots(slot_preds_list, max_seq_len=MAX_LEN)\n",
        "\n",
        "    # ========== PASS 2: Predict tag-intents with predicted masks ==========\n",
        "    tag_intent_preds = []\n",
        "    out_tag_intent_ids = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for idx, tokens in enumerate(dataset_sentences):\n",
        "        with torch.no_grad():\n",
        "            # Prepare input\n",
        "            input_ids, attention_mask, token_type_ids, word_positions = \\\n",
        "                align_tokens_for_inference(tokens, tokenizer)\n",
        "\n",
        "            batch_size, seq_len = input_ids.shape\n",
        "\n",
        "            # Get predicted masks for this sample\n",
        "            B_mask = B_tag_mask_pred_tensor[idx].numpy().tolist()  # ← THÊM DÒNG NÀY\n",
        "            BI_mask = BI_tag_mask_pred_tensor[idx].numpy().tolist()\n",
        "\n",
        "            # Align to subwords\n",
        "            B_mask_tensor = align_masks_to_subwords(B_mask, word_positions, seq_len)  # ← THÊM DÒNG NÀY\n",
        "            B_mask_tensor = B_mask_tensor.unsqueeze(0).to(DEVICE).long()  # ← THÊM DÒNG NÀY\n",
        "\n",
        "            BI_mask_tensor = align_masks_to_subwords(BI_mask, word_positions, seq_len)\n",
        "            BI_mask_tensor = BI_mask_tensor.unsqueeze(0).to(DEVICE)\n",
        "\n",
        "            # KHÔNG CÒN: B_mask_tensor = None  ← XÓA DÒNG NÀY\n",
        "            tag_intent_label = torch.full((1, NUM_MASK), IGNORE_INDEX, dtype=torch.long, device=DEVICE)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids,\n",
        "                intent_label_ids=None,\n",
        "                slot_labels_ids=None,\n",
        "                intent_token_ids=None,\n",
        "                B_tag_mask=B_mask_tensor,  # ← BÂY GIỜ KHÔNG PHẢI None\n",
        "                BI_tag_mask=BI_mask_tensor,\n",
        "                tag_intent_label=tag_intent_label\n",
        "            )\n",
        "\n",
        "            # Extract tag-intent predictions\n",
        "            if outputs[\"tag_intent_logits\"] is not None:\n",
        "                tag_intent_logits = outputs[\"tag_intent_logits\"].view(NUM_MASK, -1)\n",
        "                tag_intent_pred = torch.argmax(tag_intent_logits, dim=-1).cpu().numpy()\n",
        "\n",
        "                # Convert to labels\n",
        "                pred_labels = []\n",
        "                for pred_id in tag_intent_pred:\n",
        "                    pred_label = ID2TAGINT.get(pred_id, \"PAD\")\n",
        "                    pred_labels.append(pred_label)\n",
        "\n",
        "                tag_intent_preds.append(pred_labels)\n",
        "            else:\n",
        "                tag_intent_preds.append([\"PAD\"] * NUM_MASK)\n",
        "\n",
        "            # Gold tag intents\n",
        "            gold_labels = []\n",
        "            for label_id in dataset_tag_intents[idx]:\n",
        "                gold_label = ID2TAGINT.get(label_id, \"PAD\")\n",
        "                gold_labels.append(gold_label)\n",
        "            out_tag_intent_ids.append(gold_labels)\n",
        "\n",
        "    # ========== Compute metrics ==========\n",
        "    intent_token_map = {i: label for i, label in enumerate(INTENT_LABELS)}\n",
        "\n",
        "    # Format predictions to match repo format\n",
        "    out_intent_token_list = out_intent_token_ids\n",
        "    intent_token_preds_list = intent_token_preds\n",
        "    out_tag_intent_list = out_tag_intent_ids\n",
        "    tag_intent_preds_list = tag_intent_preds\n",
        "\n",
        "    # Compute all metrics\n",
        "    total_result = compute_metrics_multi_intent_fixed(\n",
        "        intent_preds,\n",
        "        out_intent_label_ids,\n",
        "        slot_preds_list,\n",
        "        out_slot_label_list,\n",
        "        intent_token_preds_list,\n",
        "        out_intent_token_list,\n",
        "        tag_intent_preds_list,\n",
        "        out_tag_intent_list\n",
        "    )\n",
        "\n",
        "    # ✅ THÊM: Compute semantic basic accuracy\n",
        "    semantic_basic_result = get_semantic_basic_acc(\n",
        "        intent_preds,\n",
        "        out_intent_label_ids,\n",
        "        slot_preds_list,\n",
        "        out_slot_label_list\n",
        "    )\n",
        "\n",
        "    # ✅ THÊM: Merge results\n",
        "    results = total_result\n",
        "    results.update(semantic_basic_result)  # Thêm semantic_basic_acc vào results\n",
        "\n",
        "    # ✅ SỬA: Uncomment và tạo predictions dictionary\n",
        "    predictions = {\n",
        "        \"intents\": intent_preds.tolist(),  # Convert tensor to list\n",
        "        \"slots\": slot_preds_list,\n",
        "        \"tokints\": intent_token_preds_list,\n",
        "        \"tag_intents\": tag_intent_preds_list\n",
        "    }\n",
        "\n",
        "    # ✅ SỬA: Thêm predictions vào results\n",
        "    results[\"predictions\"] = predictions\n",
        "\n",
        "\n",
        "    print(\"***** Eval results *****\")\n",
        "    for key in sorted(results.keys()):\n",
        "        if isinstance(results[key], (int, float)):  # Only format numbers\n",
        "            print(f\"  {mode}_{key} = {results[key]:.4f}\")\n",
        "        else:\n",
        "            print(f\"  {mode}_{key} = {type(results[key])}\")  # Show type for non-numeric values\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"✅ 2-Pass Evaluation Module Ready (Y CHANG REPO GỐC)!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zZCt-1ww3yQ",
        "outputId": "39f2b782-7514-4d98-a97d-7dfdafe39d78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 FULL SLIM INFERENCE DEMO\n",
            "================================================================================\n",
            "Model: vinai/phobert-base-v2\n",
            "Threshold: 0.5\n",
            "Schema: 5 intents, 17 slots, 6 token-intents\n",
            "Features: CRF=False, Tag-Intent=4 masks, Intent-Attn=True\n",
            "================================================================================\n",
            "\n",
            "Example 1:\n",
            "Tokens:        Tôi vừa chi 2 triệu cho ăn_uống\n",
            "Utter intents: ['add_expense']\n",
            "Slots:         O O O B-target_price I-target_price O B-target_description\n",
            "Tok-intents:   O O O add_expense add_expense O add_expense\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 2:\n",
            "Tokens:        Thống_kê chi_tiêu tháng này\n",
            "Utter intents: ['stat_expense']\n",
            "Slots:         O B-condition_description B-condition_date I-condition_date\n",
            "Tok-intents:   O stat_expense stat_expense stat_expense\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 3:\n",
            "Tokens:        Tìm giao_dịch ăn_trưa hôm_qua\n",
            "Utter intents: ['search_expense']\n",
            "Slots:         O O B-condition_description B-condition_date\n",
            "Tok-intents:   O O search_expense search_expense\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 4:\n",
            "Tokens:        Sửa tiền_điện tháng_7 thành 900 nghìn\n",
            "Utter intents: ['update_expense']\n",
            "Slots:         O B-condition_description B-condition_date O B-target_price I-target_price\n",
            "Tok-intents:   O update_expense update_expense O update_expense update_expense\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 5:\n",
            "Tokens:        Xoá giao_dịch tại Hà_Nội\n",
            "Utter intents: ['delete_expense']\n",
            "Slots:         O O O B-condition_location\n",
            "Tok-intents:   O O O delete_expense\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 6:\n",
            "Tokens:        Tôi vừa giao_dịch 2 triệu , xoá giao_dịch 3 triệu hôm_qua\n",
            "Utter intents: ['add_expense', 'delete_expense']\n",
            "Slots:         O O O B-target_price I-target_price O O O B-condition_price I-condition_price B-condition_date\n",
            "Tok-intents:   O O O add_expense add_expense O O O delete_expense delete_expense delete_expense\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 7:\n",
            "Tokens:        Xoá giao_dịch tại Hà_Nội , thêm 3 triệu tiền cơm\n",
            "Utter intents: ['add_expense', 'delete_expense']\n",
            "Slots:         O O O B-condition_location O O B-target_price I-target_price O B-target_description\n",
            "Tok-intents:   O O O delete_expense O O add_expense add_expense O add_expense\n",
            "------------------------------------------------------------\n",
            "Demo completed! ✅\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# 11) INFERENCE DEMO ON SAMPLE SENTENCES\n",
        "# ================================\n",
        "\n",
        "# Demo examples (Vietnamese pre-tokenized sentences)\n",
        "demo_examples = [\n",
        "    [\"Tôi\", \"vừa\", \"chi\", \"2\", \"triệu\", \"cho\", \"ăn_uống\"],\n",
        "    [\"Thống_kê\", \"chi_tiêu\", \"tháng\", \"này\"],\n",
        "    [\"Tìm\", \"giao_dịch\", \"ăn_trưa\", \"hôm_qua\"],\n",
        "    [\"Sửa\", \"tiền_điện\", \"tháng_7\", \"thành\", \"900\", \"nghìn\"],\n",
        "    [\"Xoá\", \"giao_dịch\", \"tại\", \"Hà_Nội\"],\n",
        "    [\"Tôi\", \"vừa\", \"giao_dịch\", \"2\", \"triệu\", \",\", \"xoá\", \"giao_dịch\", \"3\", \"triệu\", \"hôm_qua\"],\n",
        "    [\"Xoá\", \"giao_dịch\", \"tại\", \"Hà_Nội\", \",\", \"thêm\", \"3\", \"triệu\", \"tiền\", \"cơm\"]\n",
        "]\n",
        "\n",
        "print(\"🚀 FULL SLIM INFERENCE DEMO\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Threshold: {UTT_THRESHOLD}\")\n",
        "print(f\"Schema: {len(INTENT_LABELS)} intents, {len(SLOT_LABELS)} slots, {len(TOKEN_INTENT_LABELS)} token-intents\")\n",
        "print(f\"Features: CRF={model.use_crf}, Tag-Intent={model.num_mask} masks, Intent-Attn={model.intent_attn}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for i, tokens in enumerate(demo_examples, 1):\n",
        "    print(f\"\\nExample {i}:\")\n",
        "    prediction = predict_full_slim(tokens, threshold=UTT_THRESHOLD)\n",
        "    show_prediction(tokens, prediction)\n",
        "\n",
        "print(\"Demo completed! ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGgVR9p5xOZx",
        "outputId": "2d0106a1-77de-455b-d6ff-11bba4257ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RUNNING FULL EVALUATION ON TEST SET\n",
            "================================================================================\n",
            "Loaded 115 examples from /content/drive/MyDrive/dataset/vped/test\n",
            "Sample: tokens=['Tôi', 'vừa', 'chi', '200', 'nghìn'], intents=['add_expense'], slots=['O', 'O', 'O', 'B-target_price', 'I-target_price']\n",
            "Loaded 115 examples from /content/drive/MyDrive/dataset/vped/test\n",
            "Sample: tokens=['Tôi', 'vừa', 'chi', '200', 'nghìn'], intents=['add_expense'], slots=['O', 'O', 'O', 'B-target_price', 'I-target_price']\n",
            "Loaded 115 examples from /content/drive/MyDrive/dataset/vped/test\n",
            "Sample: tokens=['Tôi', 'vừa', 'chi', '200', 'nghìn'], intents=['add_expense'], slots=['O', 'O', 'O', 'B-target_price', 'I-target_price']\n",
            "Loaded 115 examples from /content/drive/MyDrive/dataset/vped/test\n",
            "Sample: tokens=['Tôi', 'vừa', 'chi', '200', 'nghìn'], intents=['add_expense'], slots=['O', 'O', 'O', 'B-target_price', 'I-target_price']\n",
            "Loaded 115 examples from /content/drive/MyDrive/dataset/vped/test\n",
            "Sample: tokens=['Tôi', 'vừa', 'chi', '200', 'nghìn'], intents=['add_expense'], slots=['O', 'O', 'O', 'B-target_price', 'I-target_price']\n",
            "***** Running evaluation on test dataset *****\n",
            "  Num examples = 115\n",
            "***** Eval results *****\n",
            "  test_intent_acc = 0.9043\n",
            "  test_intent_slot_acc = 0.5826\n",
            "  test_intent_token_f1 = 0.8044\n",
            "  test_intent_token_precision = 0.8134\n",
            "  test_intent_token_recall = 0.7956\n",
            "  test_predictions = <class 'dict'>\n",
            "  test_semantic_basic_acc = 0.5826\n",
            "  test_sementic_frame_acc = 0.5565\n",
            "  test_slot_f1 = 0.8743\n",
            "  test_slot_precision = 0.8721\n",
            "  test_slot_recall = 0.8766\n",
            "  test_tag_intent_acc = 0.9444\n",
            "Loaded 115 examples from /content/drive/MyDrive/dataset/vped/test\n",
            "Sample: tokens=['Tôi', 'vừa', 'chi', '200', 'nghìn'], intents=['add_expense'], slots=['O', 'O', 'O', 'B-target_price', 'I-target_price']\n",
            "\n",
            "SUMMARY:\n",
            "  Best metric - Intent Acc:       0.9043\n",
            "  Best metric - Slot F1:          0.8743\n",
            "  Best metric - Joint Acc Basic:  0.5826\n",
            "  Best metric - Joint Acc Exact:  0.5565\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# 12) FULL EVALUATION ON TEST SET\n",
        "# ================================\n",
        "\n",
        "# Run complete evaluation\n",
        "print(\"RUNNING FULL EVALUATION ON TEST SET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "evaluation_results = evaluate_2pass(mode='test')\n",
        "\n",
        "test_data = load_data_with_masks(TEST_DIR, is_test=True)\n",
        "\n",
        "print(\"\\nSUMMARY:\")\n",
        "print(f\"  Best metric - Intent Acc:       {evaluation_results['intent_acc']:.4f}\")\n",
        "print(f\"  Best metric - Slot F1:          {evaluation_results['slot_f1']:.4f}\")\n",
        "print(f\"  Best metric - Joint Acc Basic:  {evaluation_results['semantic_basic_acc']:.4f}\")\n",
        "print(f\"  Best metric - Joint Acc Exact:  {evaluation_results['sementic_frame_acc']:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "vslim_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.24"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05000d582ffb4da8b6d5666486c6d2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c181b1112ac4892a3c324859b514f97",
            "placeholder": "​",
            "style": "IPY_MODEL_cd915704a2944e95b454cc8bca9524e1",
            "value": " 540M/540M [00:12&lt;00:00, 82.6MB/s]"
          }
        },
        "0a9a8a7248a24550b30c61bd36f54641": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0df020eae3de454384138a355b0612bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54f2bc095ea0490a83c7606cd167ffb5",
            "placeholder": "​",
            "style": "IPY_MODEL_61b108221d5e4916af7637342c925d19",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "0feaad1dfeff4d71b3f1af45c9ea25c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1060d4416df349e4ba7442109e886476": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "16d5460ce5b2479dbf2aeb79800f9231": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b133f565377494da1fbc9516d77c3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1060d4416df349e4ba7442109e886476",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76bd0aa10b284d21b3c1bf1420001c5e",
            "value": 1
          }
        },
        "208ad7e94adb4872b90e92d01d3e21dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26d7dc9102e24c37a80ea115eeccd3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a9a8a7248a24550b30c61bd36f54641",
            "placeholder": "​",
            "style": "IPY_MODEL_b71cec8295cd4e40a5ebdfc968388807",
            "value": " 3.13M/? [00:00&lt;00:00, 36.8MB/s]"
          }
        },
        "273e70edb1d5432db9ba1297dee85d5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cafcd1766b94c65b0c8b154ab5b4241": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80106b3e9a8748fabd99ab7c18b82989",
              "IPY_MODEL_9d851b57e1e5434982e90ca02c5251b2",
              "IPY_MODEL_26d7dc9102e24c37a80ea115eeccd3dd"
            ],
            "layout": "IPY_MODEL_e574066242d240f28c03a7e09762e7ea"
          }
        },
        "2db195491c5e4feb93f1922defc135f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8a4a36d48544c9fb3130a7a7b522b47",
              "IPY_MODEL_c2c5db9497024bf28e4bd4e9173ca196",
              "IPY_MODEL_3ac7cc8e1d7b4aec9af40f7458747d25"
            ],
            "layout": "IPY_MODEL_afd3f46d5e9c464da583b937aa160a83"
          }
        },
        "3346a4779df54fb3aa089bc336c929ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3931f37e24214398bfa1804f4c4e4170": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ac7cc8e1d7b4aec9af40f7458747d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_640627432f99449a9d1fe8ea967b579b",
            "placeholder": "​",
            "style": "IPY_MODEL_fdd342be8d3244c38c41cee8a819a2e2",
            "value": " 895k/? [00:00&lt;00:00, 14.1MB/s]"
          }
        },
        "3bf014ae5b544acf969fd7568f3ef8da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "438c973005dd4b8d852bcd3a186ce611": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0df020eae3de454384138a355b0612bf",
              "IPY_MODEL_87e86c7926dc4bdf84a050186cde31bd",
              "IPY_MODEL_05000d582ffb4da8b6d5666486c6d2ef"
            ],
            "layout": "IPY_MODEL_dbbeb636bd784267b42ce3b738a3f15c"
          }
        },
        "4f0fce78310945678831abb7cfc689d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa0d150ee7384c90923d1d27c30d8519",
            "placeholder": "​",
            "style": "IPY_MODEL_88dbfcff1e56429daa43a67b459b7fe7",
            "value": "bpe.codes: "
          }
        },
        "5457a3e06236462b9d1b9c6a1c666a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_273e70edb1d5432db9ba1297dee85d5e",
            "placeholder": "​",
            "style": "IPY_MODEL_b28f107bd3c24449bcfd8250f2628f6d",
            "value": " 1.14M/? [00:00&lt;00:00, 14.9MB/s]"
          }
        },
        "54f2bc095ea0490a83c7606cd167ffb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61b108221d5e4916af7637342c925d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "640627432f99449a9d1fe8ea967b579b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76bd0aa10b284d21b3c1bf1420001c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76ecafc616aa4f4f94b2ca388f95f0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79e54c3d052847ec879c513dd0ae9694": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80106b3e9a8748fabd99ab7c18b82989": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99479b00883f44798f7a98fc624af821",
            "placeholder": "​",
            "style": "IPY_MODEL_c9dd39faa0ac44969fd63dae4fe82942",
            "value": "tokenizer.json: "
          }
        },
        "81cdeeb6be78491a83528d7a4066cb53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f0fce78310945678831abb7cfc689d8",
              "IPY_MODEL_1b133f565377494da1fbc9516d77c3f2",
              "IPY_MODEL_5457a3e06236462b9d1b9c6a1c666a2b"
            ],
            "layout": "IPY_MODEL_3931f37e24214398bfa1804f4c4e4170"
          }
        },
        "87e86c7926dc4bdf84a050186cde31bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df12c3f6cd7c4a9087e694bd0498bc11",
            "max": 540322347,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a36807101c3948759794c9ed63e60468",
            "value": 540322347
          }
        },
        "88dbfcff1e56429daa43a67b459b7fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e1957c93868453ea08eda21b929feff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbf0620bb1f442548beeca73ec7354f4",
              "IPY_MODEL_d0ddf793a0f64829a18afb54356e1a4a",
              "IPY_MODEL_d7e9912ccf6047fc898fa8fef19bf9e5"
            ],
            "layout": "IPY_MODEL_208ad7e94adb4872b90e92d01d3e21dc"
          }
        },
        "90f274c6dfb94488af54d9260241484b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99479b00883f44798f7a98fc624af821": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c181b1112ac4892a3c324859b514f97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d851b57e1e5434982e90ca02c5251b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffd8b21207f44bac8e24d9c39c41809c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcf38104039749e7b08896eb22df8723",
            "value": 1
          }
        },
        "a36807101c3948759794c9ed63e60468": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8a4a36d48544c9fb3130a7a7b522b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bf014ae5b544acf969fd7568f3ef8da",
            "placeholder": "​",
            "style": "IPY_MODEL_79e54c3d052847ec879c513dd0ae9694",
            "value": "vocab.txt: "
          }
        },
        "aa0d150ee7384c90923d1d27c30d8519": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afd3f46d5e9c464da583b937aa160a83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b28f107bd3c24449bcfd8250f2628f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b71cec8295cd4e40a5ebdfc968388807": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcf38104039749e7b08896eb22df8723": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2c5db9497024bf28e4bd4e9173ca196": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcda3e38394c4c78a19a085ef0fee33e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cffdd3e01dad415a90cd34f91d1b3113",
            "value": 1
          }
        },
        "c9dd39faa0ac44969fd63dae4fe82942": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd915704a2944e95b454cc8bca9524e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cffdd3e01dad415a90cd34f91d1b3113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0ddf793a0f64829a18afb54356e1a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16d5460ce5b2479dbf2aeb79800f9231",
            "max": 678,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76ecafc616aa4f4f94b2ca388f95f0da",
            "value": 678
          }
        },
        "d7e9912ccf6047fc898fa8fef19bf9e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb7815a357464954b7dbfe82f2cfb819",
            "placeholder": "​",
            "style": "IPY_MODEL_0feaad1dfeff4d71b3f1af45c9ea25c2",
            "value": " 678/678 [00:00&lt;00:00, 51.7kB/s]"
          }
        },
        "dbbeb636bd784267b42ce3b738a3f15c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf0620bb1f442548beeca73ec7354f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3346a4779df54fb3aa089bc336c929ad",
            "placeholder": "​",
            "style": "IPY_MODEL_90f274c6dfb94488af54d9260241484b",
            "value": "config.json: 100%"
          }
        },
        "df12c3f6cd7c4a9087e694bd0498bc11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e574066242d240f28c03a7e09762e7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb7815a357464954b7dbfe82f2cfb819": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcda3e38394c4c78a19a085ef0fee33e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fdd342be8d3244c38c41cee8a819a2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffd8b21207f44bac8e24d9c39c41809c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
